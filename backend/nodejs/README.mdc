# BrandBloom Insights Backend

A modular Node.js backend service for handling file uploads, data processing, and metadata management for the BrandBloom Insights analytics platform.

## ğŸ—ï¸ Architecture Overview

This backend follows a **ultra-modular design** where each file has a single responsibility:

```
backend/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ constants.js           # Application configuration
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ fileValidator.js       # File validation utilities
â”‚   â””â”€â”€ timestampGenerator.js  # Timestamp generation utilities
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ fileUploadHandler.js   # File upload processing
â”‚   â”œâ”€â”€ fileReader.js          # File reading and column extraction
â”‚   â”œâ”€â”€ filterManager.js       # Filter column management
â”‚   â”œâ”€â”€ metadataManager.js     # Metadata Excel file operations
â”‚   â””â”€â”€ brandHandler.js        # Brand name processing
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ fileRoutes.js          # File upload endpoints
â”‚   â”œâ”€â”€ filterRoutes.js        # Filter management endpoints
â”‚   â”œâ”€â”€ brandRoutes.js         # Brand management endpoints
â”‚   â””â”€â”€ metadataRoutes.js      # Metadata management endpoints
â”œâ”€â”€ uploads/                   # Temporary upload directory
â”œâ”€â”€ processed/                 # Timestamped processed files
â”œâ”€â”€ metadata/                  # Metadata Excel files
â””â”€â”€ server.js                  # Main server entry point
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- npm or yarn

### Installation

```bash
# Navigate to backend directory
cd backend

# Install dependencies
npm install

# Start the server
npm start

# For development with auto-reload
npm run dev
```

The server will start at `http://localhost:3001`

## ğŸ“‹ Core Functionality

### 1. File Upload & Processing

**Workflow:**
1. User uploads `.xlsx` or `.csv` file
2. File is validated (size, type)
3. Copy created with timestamp: `<UploadedFileName>_<timestamp>.xlsx`
4. File stored in `./processed/` directory
5. Metadata file created: `<uploadedFileName>_metadata_<timestamp>.xlsx`

**API Endpoints:**
- `POST /api/v1/files/upload` - Upload and process file
- `GET /api/v1/files/:filename/columns` - Get file columns
- `GET /api/v1/files/:filename/sample` - Get sample data

### 2. Column Reading & Analysis

**Capabilities:**
- Extracts column names from Excel/CSV files
- Provides file statistics (rows, columns)
- Generates sample data preview
- Handles various file formats gracefully

### 3. Filter Column Selection

**Features:**
- Validates column selections
- Provides intelligent column suggestions
- Stores selections in metadata file
- Tracks selection history

**API Endpoints:**
- `GET /api/v1/filters/:filename/suggestions` - Get suggested columns
- `POST /api/v1/filters/:filename/validate` - Validate selection
- `POST /api/v1/filters/:filename/save` - Save to metadata

### 4. Brand Name Management

**Functionality:**
- Validates brand name input
- Provides formatting suggestions
- Stores brand info in metadata
- Tracks brand entry history

**API Endpoints:**
- `POST /api/v1/brands/validate` - Validate brand name
- `POST /api/v1/brands/save` - Save brand to metadata
- `PUT /api/v1/brands/update` - Update brand name

### 5. Metadata Management

**Metadata File Structure:**
- **FileInfo Sheet**: Original file information
- **FilterColumns Sheet**: Selected filter columns
- **BrandInfo Sheet**: Brand name and details
- **ProcessingLog Sheet**: All processing activities

**API Endpoints:**
- `POST /api/v1/metadata/create` - Create metadata file
- `GET /api/v1/metadata/:filename/info` - Get metadata info
- `GET /api/v1/metadata/:filename/download` - Download metadata

## ğŸ”§ Configuration

### Environment Variables

```bash
# Server Configuration
PORT=3001
HOST=localhost
NODE_ENV=development

# File Configuration (optional - defaults in constants.js)
MAX_FILE_SIZE=10485760  # 10MB
UPLOAD_DIR=./uploads
PROCESSED_DIR=./processed
METADATA_DIR=./metadata
```

### Constants Configuration

Edit `config/constants.js` to modify:
- File size limits
- Allowed file extensions
- Directory paths
- Excel sheet names

## ğŸ“ File Management

### Directory Structure

```
backend/
â”œâ”€â”€ uploads/     # Temporary files (cleaned after processing)
â”œâ”€â”€ processed/   # Timestamped copies of uploaded files
â””â”€â”€ metadata/    # Excel files with processing metadata
```

### File Naming Convention

- **Processed Files**: `OriginalName_YYYYMMDD_HHMMSS.xlsx`
- **Metadata Files**: `OriginalName_metadata_YYYYMMDD_HHMMSS.xlsx`

## ğŸ” API Documentation

### Standard Response Format

```json
{
  "success": true|false,
  "message": "Human readable message",
  "data": { /* Response data */ },
  "error": "Error message (if success=false)"
}
```

### Example Usage

#### Upload File
```bash
curl -X POST http://localhost:3001/api/v1/files/upload \
  -F "file=@data.xlsx"
```

#### Get Columns
```bash
curl http://localhost:3001/api/v1/files/data_20241220_143022.xlsx/columns
```

#### Save Filter Selection
```bash
curl -X POST http://localhost:3001/api/v1/filters/data_20241220_143022.xlsx/save \
  -H "Content-Type: application/json" \
  -d '{
    "selectedColumns": ["Date", "Revenue", "TV_Spend"],
    "metadataFilename": "data_metadata_20241220_143022.xlsx"
  }'
```

#### Save Brand Name
```bash
curl -X POST http://localhost:3001/api/v1/brands/save \
  -H "Content-Type: application/json" \
  -d '{
    "brandName": "Nike",
    "metadataFilename": "data_metadata_20241220_143022.xlsx"
  }'
```

## ğŸ§ª Testing

### Health Check
```bash
curl http://localhost:3001/health
```

### API Documentation
```bash
curl http://localhost:3001/api/v1
```

## ğŸ› ï¸ Development

### Adding New Features

The modular structure makes it easy to extend:

1. **New Service**: Add to `services/` directory
2. **New Routes**: Add to `routes/` directory  
3. **New Utilities**: Add to `utils/` directory
4. **New Config**: Update `config/constants.js`

### Code Standards

- **Single Responsibility**: Each file does one thing
- **Clear Naming**: Descriptive function and variable names
- **Error Handling**: Consistent error response format
- **Documentation**: JSDoc comments for all functions
- **Validation**: Input validation for all endpoints

## ğŸ”’ Security Considerations

- File type validation
- File size limits
- Input sanitization
- Path traversal protection
- CORS configuration

## ğŸ“Š Monitoring

### Logs
- Request logging (timestamp, method, path)
- Error logging with stack traces
- Processing activity logging

### Health Checks
- Directory accessibility
- Service availability
- File system permissions

## ğŸš€ Deployment

### Production Setup
1. Set `NODE_ENV=production`
2. Configure proper file permissions
3. Set up log rotation
4. Configure reverse proxy (nginx)
5. Set up monitoring and alerts

### Docker Support
```dockerfile
# Dockerfile example
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3001
CMD ["npm", "start"]
```

## ğŸ”® Future Enhancements

- Database integration for metadata
- File encryption/security
- Batch processing capabilities
- Real-time processing status
- Integration with cloud storage
- Advanced file format support
- User authentication system
- Role-based access control

## ğŸ“ Support

For issues or questions:
1. Check the API documentation: `GET /api/v1`
2. Verify health status: `GET /health`
3. Review server logs
4. Check file permissions and directory access

## ğŸ“„ License

This project is part of the BrandBloom Insights platform.