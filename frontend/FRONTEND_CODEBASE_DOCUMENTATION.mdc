# BrandBloom Insights Frontend Codebase Documentation

## 🆕 New Features (2025-10-03)

### ✅ Persistent Data Structure Summary Component (2025-10-03)

#### Overview:
Added a persistent data structure summary component that displays column names, row count, and helpful guidance throughout the non-MMM analysis workflow. This component addresses the user's need to have constant visibility of their data structure after CSV upload.

#### Component Details:

**DataStructureSummary Component** (`frontend/src/components/DataStructureSummary.tsx`):
- **Purpose**: Display persistent summary of uploaded data structure
- **Props**:
  - `columns`: Array of column names from the dataset
  - `rowCount`: Total number of rows in the dataset
  - `className`: Optional className for styling
- **Features**:
  - Shows total columns and rows with file icon
  - Displays column names as interactive pill-style tags
  - Includes lightbulb icon with helpful guidance text
  - Consistent styling with brand design
  - Persists across analysis steps

#### Integration Points:

**NonMMMDataSummaryStep** (`frontend/src/analysis/nonmmm/steps/NonMMMDataSummaryStep.tsx`):
- Added component right after header section
- Displays all variable names and row count
- Visible throughout all sub-steps (Target Variable, Statistical Summary, Histograms, Correlation Matrix)

**NonMMMChartAnalysisStep** (`frontend/src/analysis/nonmmm/steps/NonMMMChartAnalysisStep.tsx`):
- Added component after hero header
- Shows target variable and all independent variables
- Provides context during chart analysis

**NonMMMModelBuildingStep** (`frontend/src/analysis/nonmmm/steps/NonMMMModelBuildingStep.tsx`):
- Added component after header section
- Displays target variable and available independent variables
- Helps users understand data structure during modeling

#### User Benefits:
1. **Constant Visibility**: Users always know what columns are in their dataset
2. **Data Context**: Provides quick reference without scrolling
3. **Professional UI**: Matches brand design with clean, modern styling
4. **Helpful Guidance**: Lightbulb icon with text encourages user interaction
5. **Persistent Display**: Component doesn't disappear during analysis workflow

#### Technical Implementation:
- Reusable React component with TypeScript
- Uses shadcn/ui components (Card, Badge)
- Lucide React icons (FileText, Lightbulb)
- Tailwind CSS for styling
- Responsive design that works on all screen sizes

## 🆕 New Features (2025-01-31)

### ✅ PROJECT B Dashboard Integration (2025-01-31)

#### Integration Overview:
The main BrandBloom Insights application now integrates with PROJECT B (Marico Insight Dashboarding) to provide advanced analytics capabilities for Brand Leaders. When users click "Analyze Dashboards" and select "Brand Leader", they can access the sophisticated dashboard application.

#### Key Integration Features:
1. **Seamless Navigation**: Click "Analyze Dashboards" → "Brand Leader" → "Access Dashboard Analytics"
2. **New Tab Opening**: PROJECT B opens in a new tab for better user experience
3. **Environment Handling**: Automatic URL management for development vs production
4. **Loading States**: Visual feedback during navigation with loading indicators
5. **Error Handling**: Graceful fallback if PROJECT B is not available

#### Technical Implementation:

**Navigation Utility (`navigationUtils.ts`)**:
- `navigateToDashboard()`: Opens PROJECT B in new tab
- `checkDashboardAvailability()`: Verifies PROJECT B is running
- `getDashboardUrl()`: Returns appropriate URL for environment
- Handles development (localhost:8082) vs production URLs
- Provides fallback navigation if popup is blocked

**BrandLeaderWizard Updates**:
- Added "Access Dashboard Analytics" button with loading states
- Updated features list to reflect actual PROJECT B capabilities
- Integrated navigation utility for seamless connection
- Added loading indicators and error handling

**PROJECT B Configuration**:
- Configured to run on port 8082 (vite.config.ts)
- Created startup script (start-dashboard.sh)
- Added comprehensive integration documentation
- Created test script for verification

#### User Flow:
1. User visits main app (localhost:8081)
2. Clicks "Analyze Dashboards" button
3. PROJECT B opens directly in new tab (localhost:8082)
4. User can work with advanced analytics and dashboards
5. No intermediate steps - direct access to dashboard application

#### Development Setup:
```bash
# Terminal 1 - Main App
cd frontend && npm run dev  # Port 8081

# Terminal 2 - PROJECT B
cd "PROJECT B/maricoinsight-Dashboarding" && npm run dev  # Port 8082
```

#### Testing:
```bash
# Run integration test
node test-integration.js
```

#### Deployment Strategy:
- **Development**: Both apps run locally (ports 8081, 8082)
- **Production**: Deploy to separate Azure Static Web Apps
- **URL Management**: Automatic environment detection
- **Scalability**: Independent scaling and deployment

### ✅ Chart Analysis Step Performance Optimizations (2025-01-31)

#### Performance Issues Fixed:
1. **Trendline Type Undefined**: Fixed trendlineType being undefined in chart containers by setting default value to 'linear'
2. **Unnecessary Re-rendering**: Removed problematic guardrails and optimized useEffect dependencies to prevent multiple re-renders
3. **Excessive Backend Calls**: Added debounce mechanism to state synchronization to prevent multiple backend requests
4. **Duplicate Console Logs**: Removed excessive debug logging that was causing duplicate console output
5. **Component Re-rendering**: Eliminated unnecessary re-renders by removing stateLoadedRef guardrail and optimizing dependencies
6. **Post-Standardization Re-renders**: Added preventRerenderRef to prevent re-renders after auto-standardization
7. **Chart Container Duplicate Logs**: Moved chart container debug logging into useEffect to prevent duplicate output
8. **Redundant State Cleanup**: Removed all unnecessary isGenerating state variables and refs that were causing confusion

#### Key Improvements:

**NonMMMChartAnalysisStep.tsx**:
- Removed `stateLoadedRef` guardrail that was causing re-renders
- Set default `trendlineType: 'linear'` for all charts during generation and hydration
- Optimized useEffect dependencies to prevent unnecessary re-renders
- Moved debug logging into useEffect to prevent render-time logging
- Simplified chart generation logic by removing complex guardrails
- Removed all redundant `isGenerating` state variables and refs
- Removed `preventRerenderRef` and simplified state management
- Cleaned up unnecessary state variables and refs for better maintainability

**NonMMMStateService.ts**:
- Added debounce mechanism with 2-second delay for backend sync calls
- Prevents excessive backend requests during rapid state access
- Maintains data freshness while reducing server load

**NonMMMChartContainer.tsx**:
- Fixed trendline calculation to handle undefined trendlineType gracefully
- Improved chart rendering performance with better memoization
- Removed excessive debug logging that was causing duplicate console output
- Wrapped calculateTrendline in useCallback to prevent unnecessary recalculations
- Consolidated multiple console.log statements into single debug output
- Moved chart container debug logging into useEffect to prevent duplicate output
- Optimized dependency arrays to prevent unnecessary re-calculations

#### Technical Details:

**State Management Optimization:**
```typescript
// Debounce sync calls to prevent excessive backend requests
private static lastSyncTime = 0;
private static syncDebounceMs = 2000; // 2 seconds debounce

// Only sync with backend if enough time has passed since last sync
const now = Date.now();
if (localState.analysisId && (now - NonMMMStateService.lastSyncTime) > NonMMMStateService.syncDebounceMs) {
  NonMMMStateService.lastSyncTime = now;
  NonMMMStateService.syncWithBackend(localState.analysisId).catch(error => {
    console.warn('⚠️ Failed to sync with backend:', error);
  });
}
```

**Chart Hydration Optimization:**
```typescript
// Ensure trendlineType is set for all charts
const hydratedCharts = savedChartData.map(chart => ({
  ...chart,
  trendlineType: chart.trendlineType || 'linear'
}));
```

**Re-render Prevention:**
```typescript
// Prevent multiple state loads
if (stateLoadedRef.current) return;

// Prevent duplicate chart hydration
if (nonmmmState && analysisId && !chartsGeneratedRef.current) {
  // Process charts only once
}
```

#### Performance Impact:
- **Reduced Re-renders**: Eliminated unnecessary component re-renders
- **Faster Loading**: Optimized state loading and chart hydration
- **Reduced Backend Load**: 2-second debounce prevents excessive API calls
- **Better User Experience**: Smoother chart interactions and faster page loads

### ✅ Chart Copy to Clipboard Functionality (2025-01-31)

#### Feature Overview:
Implemented comprehensive chart copying functionality for Non-MMM analysis chart containers, allowing users to copy charts as high-quality images directly to their clipboard for pasting into PowerPoint presentations.

#### Key Features:
1. **One-Click Copy**: Copy button in each chart container header for instant copying
2. **One-Click Download**: Download button for saving charts as image files
3. **High-Quality Images**: 2x scale rendering for crisp, professional-quality images
4. **Clipboard Integration**: Direct clipboard copying for seamless PowerPoint integration
5. **Precise Chart Capture**: Captures only the two charts (line chart and scatter plot) without summary cards
6. **User Feedback**: Toast notifications for success and error states

#### Implementation Details:

**Updated Components:**

1. **NonMMMChartContainer.tsx**:
   - Added `Copy` icon import from lucide-react
   - Added `useToast` hook for user feedback
   - Added `chartContainerRef` for DOM element reference
   - Implemented `handleCopyChart` function with html2canvas integration
   - Added copy button to chart container header
   - Comprehensive error handling with fallback mechanisms

**Copy Functionality:**
- **Image Capture**: Uses html2canvas library to capture chart container as canvas
- **High Resolution**: 2x scale rendering for professional quality
- **Clipboard API**: Modern clipboard API for direct image copying
- **Fallback Download**: Automatic file download if clipboard fails
- **Error Handling**: Graceful error handling with user feedback

**User Experience:**
- **Visual Feedback**: Blue copy button with hover effects
- **Toast Notifications**: Success, fallback, and error messages
- **Professional Quality**: High-resolution images suitable for presentations
- **Seamless Integration**: Works with all chart types (line charts and scatter plots)
- **Accessibility**: Proper tooltips and button labels

**Technical Implementation:**
```typescript
// Copy chart container to clipboard as image
const handleCopyChart = async () => {
  if (!chartContainerRef.current) return;

  try {
    // Use html2canvas to capture the chart container as an image
    const { default: html2canvas } = await import('html2canvas');
    
    const canvas = await html2canvas(chartContainerRef.current, {
      backgroundColor: '#ffffff',
      scale: 2, // Higher resolution for better quality
      useCORS: true,
      allowTaint: true,
      logging: false,
      width: chartContainerRef.current.offsetWidth,
      height: chartContainerRef.current.offsetHeight,
    });

    // Convert canvas to blob and copy to clipboard
    canvas.toBlob(async (blob) => {
      if (blob) {
        try {
          await navigator.clipboard.write([
            new ClipboardItem({ 'image/png': blob })
          ]);
          toast({ title: "Chart Copied!", description: `Chart for ${variable} has been copied to clipboard.` });
        } catch (error) {
          // Fallback: download the image
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = `${variable}_chart.png`;
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
          toast({ title: "Chart Downloaded", description: `Chart for ${variable} has been downloaded as an image file.` });
        }
      }
    }, 'image/png');
  } catch (error) {
    toast({ title: "Copy Failed", description: `Failed to copy chart for ${variable}. Please try again.`, variant: "destructive" });
  }
};
```

**Dependencies Added:**
- `html2canvas`: For capturing DOM elements as images
- `useToast`: For user feedback notifications

#### Benefits:
- ✅ **PowerPoint Integration**: Direct copying for presentation workflows
- ✅ **Professional Quality**: High-resolution images suitable for corporate presentations
- ✅ **User-Friendly**: One-click copying with clear feedback
- ✅ **Robust Error Handling**: Fallback mechanisms ensure functionality
- ✅ **Accessibility**: Proper tooltips and visual feedback
- ✅ **Seamless UX**: Works with all existing chart functionality

### ✅ Model Building Improvements & Standardized Data (2025-01-31)

#### Feature Overview:
Implemented comprehensive improvements to the Non-MMM model building workflow, including automatic standardized data creation, enhanced model training capabilities, and improved statistical calculations for better model interpretation.

#### Key Features:
1. **Automatic Standardized Data Creation**: Seamlessly creates standardized data when moving from charting to model building
2. **Enhanced Data Type Selection**: Users can choose between original and standardized data for modeling
3. **Improved Statistical Calculations**: Fixed VIF and elasticity calculations for meaningful model interpretation
4. **Seamless Workflow Integration**: Automatic data preparation without user intervention

#### Implementation Details:

**Updated Components:**

1. **NonMMMChartAnalysisStep.tsx**:
   - Added automatic standardized data creation in `handleContinue` function
   - Integrated with Python backend `/api/nonmmm/create-standardized-data` endpoint
   - Updates Non-MMM state with standardized file information
   - Graceful error handling - continues workflow even if standardization fails
   - Uses z-score standardization by default for consistent results

2. **NonMMMModelBuildingStep.tsx**:
   - Enhanced data type selection UI with clear descriptions
   - Improved user experience for choosing between original and standardized data
   - Better visual feedback for data type selection
   - Maintains existing model training functionality

**Backend Integration:**
- **New Endpoint**: `POST /api/nonmmm/create-standardized-data`
- **File Naming**: Uses simple pattern `<rawfilename>_std.xlsx` as requested
- **Storage Location**: Stores in brand-specific standardized directory
- **Metadata Tracking**: Comprehensive metadata for standardization parameters

**Statistical Improvements:**
- **VIF Calculation**: Now uses proper statsmodels calculation instead of hardcoded values
- **Elasticity Calculation**: Fixed to use original data means for meaningful interpretation
- **Error Handling**: Comprehensive error handling with fallback values

#### User Experience:
- **Automatic Data Preparation**: No manual intervention required for standardized data creation
- **Clear Data Type Selection**: Intuitive UI for choosing between original and standardized data
- **Meaningful Statistics**: VIF and elasticity values now provide actionable insights
- **Seamless Workflow**: Smooth transition from charting to model building
- **Error Resilience**: Workflow continues even if standardization encounters issues

#### Technical Features:
- **API Integration**: Seamless integration with Python backend standardization service
- **State Management**: Proper state updates for standardized file information
- **File Resolution**: Enhanced logic for finding standardized files during model training
- **Error Handling**: Comprehensive error handling with user-friendly messages
- **Metadata Tracking**: Complete tracking of standardization parameters and results

### ✅ Variable Deletion Feature (2025-01-31)

#### Feature Overview:
Implemented comprehensive variable deletion functionality for the Non-MMM analysis charting page, allowing users to permanently remove unwanted variables from data files during the chart analysis step. This feature provides a clean and efficient way to manage variables without restarting the entire analysis.

#### Key Features:
1. **Delete Button UI**: Red trash icon button positioned to the right of the trendline dropdown
2. **Confirmation Dialog**: Browser confirmation dialog before deletion to prevent accidental removal
3. **Target Variable Protection**: Prevents deletion of the target variable to maintain analysis integrity
4. **State Synchronization**: Updates both frontend state and backend data files
5. **Immediate UI Update**: Charts are removed from the interface immediately after deletion
6. **Toast Notifications**: Clear success/error feedback to users

#### Implementation Details:

**Updated Components:**

1. **NonMMMChartContainer.tsx**:
   - Added `onDelete` prop to interface for delete functionality
   - Added delete button with red color scheme and hover effects
   - Positioned button strategically next to trendline dropdown
   - Added proper accessibility with tooltips

2. **NonMMMChartAnalysisStep.tsx**:
   - Added `handleDeleteVariable` function for delete logic
   - Implemented confirmation dialog with variable name
   - Added state management for chart removal
   - Integrated with expected signs state cleanup
   - Added comprehensive error handling and user feedback

3. **NonMMMChartAnalysisService.ts**:
   - Added `DeleteColumnResponse` interface for API response typing
   - Added `deleteColumn` method for backend API communication
   - Implemented proper error handling and response validation
   - Added URL encoding for special characters in column names

#### User Experience:
- **Clear Visual Design**: Red trash icon clearly indicates delete action
- **Confirmation Safety**: Browser confirm dialog prevents accidental deletions
- **Immediate Feedback**: Toast notifications provide clear success/error messages
- **Seamless Integration**: Delete functionality works within existing chart workflow
- **State Consistency**: Both frontend and backend states are updated simultaneously

#### Technical Features:
- **API Integration**: Calls Python backend `/api/nonmmm/delete-column/{filename}` endpoint
- **Error Handling**: Comprehensive error handling for various failure scenarios
- **Cache Busting**: Uses timestamp-based cache busting to ensure fresh data in modeling step
- **Fresh Data Loading**: Modeling step loads variables directly from updated Excel file

#### Critical Fix (2025-01-31):
**Issue Resolved**: Variable deletion was not properly updating the Excel file used for modeling due to race conditions and inconsistent file search strategies between backend endpoints.

**Frontend Improvements:**
1. **Timestamp-based Cache Busting**: Added `_t=${timestamp}` parameter to data-summary API calls in modeling step
2. **Fresh Data Loading**: Modeling step now always loads variables from the updated Excel file
3. **Automatic Refresh**: Variables are refreshed when navigating from chart analysis to modeling
4. **Consistent State**: Ensures frontend state matches the actual file contents

**Impact:**
- ✅ **Fixed Variable Deletion**: Deleted variables no longer appear in modeling step
- ✅ **Fresh Data**: Modeling step always sees the most current file state
- ✅ **Race Condition Prevention**: Eliminates inconsistencies between delete and modeling steps
- ✅ **User Experience**: Seamless workflow from chart analysis to modeling
- **State Management**: Updates local charts state and expected signs
- **File Persistence**: Permanently removes columns from Excel data files
- **Type Safety**: Full TypeScript support with proper interfaces

#### Business Logic:
- **Target Variable Protection**: Prevents deletion of the target variable by checking non-MMM state
- **File Validation**: Ensures file and column exist before deletion
- **Permanent Removal**: Uses pandas `df.drop(columns=[column_name])` for complete removal
- **State Cleanup**: Removes variable from expected signs and chart data
- **Workflow Continuity**: Maintains analysis progress after variable deletion

#### Benefits:
- ✅ **Data Cleanup**: Users can remove unwanted variables during analysis
- ✅ **Workflow Efficiency**: No need to restart analysis to remove variables
- ✅ **Target Variable Protection**: Prevents accidental deletion of critical variables
- ✅ **State Consistency**: Maintains synchronization between frontend and backend
- ✅ **User-Friendly**: Clear confirmation and feedback mechanisms
- ✅ **Permanent Removal**: Variables are completely removed from data files

### ✅ Chart Auto-Scaling and Number Formatting (2025-01-31)

#### Feature Overview:
Implemented comprehensive auto-scaling for all charts in the BrandBloom Insights application with intelligent number formatting for large values. This ensures optimal data visualization across all chart types and data ranges.

#### Key Features:
1. **Auto-Scaling for All Chart Types**: Line charts, scatter plots, and histograms now automatically scale to show all data points optimally
2. **Smart Number Formatting**: Large numbers are automatically formatted with K (Thousands), L (Lacs), and Cr (Crores) units
3. **Dual-Axis Support**: Line charts with primary and secondary axes are properly scaled independently
4. **Consistent Scaling**: All charts use the same scaling algorithm for consistent user experience
5. **Enhanced Tooltips**: Tooltips display properly formatted values with appropriate units

#### Implementation Details:

**New Utility: Chart Scaling (`frontend/src/utils/chartScaling.ts`)**
- **calculateAxisDomain()**: Calculates optimal axis domain with padding for better data visibility
- **calculateDualAxisDomain()**: Handles dual-axis line charts with independent scaling
- **calculateScatterPlotDomain()**: Optimizes scatter plot axes for X and Y data
- **Smart Unit Detection**: Automatically determines appropriate units (K/L/Cr) based on data range
- **Nice Tick Generation**: Creates clean, readable tick marks for axes
- **Custom Formatters**: Provides formatters for consistent number display

**Updated Components:**
1. **NonMMMChartContainer.tsx**: 
   - Line charts with dual Y-axes now auto-scale independently
   - Scatter plots with X and Y axes auto-scale for optimal data visibility
   - Tooltips display formatted values with proper units
   - Statistics display uses consistent formatting

2. **DataDistributionChart.tsx**:
   - Histogram Y-axes auto-scale based on frequency counts
   - Categorical bar charts auto-scale for count values
   - Improved X-axis labels with rotation for better readability
   - Enhanced tooltips with proper formatting

#### Technical Features:
- **Padding Control**: 10% padding around data range for better visualization
- **Edge Case Handling**: Proper handling of single values, empty data, and extreme ranges
- **Performance Optimized**: Efficient calculations with minimal re-renders
- **Responsive Design**: Charts maintain proper scaling across different screen sizes
- **Type Safety**: Full TypeScript support with proper interfaces

#### Number Formatting Rules:
- **Values < 1,000**: Display as whole numbers or with appropriate decimals
- **Values ≥ 1,000**: Format as "X K" (thousands)
- **Values ≥ 1,00,000**: Format as "X L" (lakhs)
- **Values ≥ 1,00,00,000**: Format as "X Cr" (crores)
- **Small Values**: Show appropriate decimal places for precision

#### Benefits:
- **Better Data Visibility**: All data points are clearly visible in charts
- **Consistent Experience**: Uniform scaling across all chart types
- **Professional Appearance**: Clean, readable axes with proper formatting
- **User-Friendly**: Large numbers are easy to read and understand
- **Responsive**: Charts adapt to different data ranges automatically

### ✅ Bug Fixes and Improvements (2025-01-31)

#### Fixed Critical Issues:
1. **NonMMMDataSummaryStep.tsx Loading Error**: Fixed 500 error when loading step 3 (Data Summary)
   - Fixed property name mismatches (`dataType` → `type`, `variable` → `name`)
   - Fixed TypeScript type errors for expected signs
   - Fixed React Hook dependency warnings
   - Fixed function declaration order issues

2. **NonMMMModelResultsStep.tsx TypeScript Error**: Fixed missing property error
   - Added `elasticity` and `elasticity10Percent` properties to `ModelVariable` interface
   - Fixed React Hook dependency warnings
   - Improved function organization with useCallback

#### Technical Details:
- **Property Mapping**: Corrected variable property references throughout data summary step
- **Type Safety**: Enhanced TypeScript interfaces for better type checking
- **React Hooks**: Fixed dependency arrays and function declarations
- **Code Organization**: Improved function ordering and useCallback usage

### ✅ Data Standardization Feature for Non-MMM Analysis (2025-01-31)

#### Feature Overview:
Added comprehensive data standardization capabilities to Non-MMM analysis workflow. Users can now standardize their data before modeling and choose between original and standardized data for model training.

#### Key Features:
1. **Data Standardization Step**: New step 5 in Non-MMM workflow between Chart Analysis and Model Building
2. **Multiple Standardization Methods**: Z-Score, Min-Max, Robust Scaling, Unit Vector
3. **Variable Selection**: Choose which variables to standardize while preserving target variable
4. **Data Type Selection**: Choose between Original or Standardized data in Model Building step
5. **Standardized File Creation**: Creates new Excel files with standardized data
6. **Metadata Tracking**: Comprehensive tracking of standardization parameters and results

#### Implementation Details:

**Backend Changes:**
- **New Service**: `DataStandardizationService` for data preprocessing
- **New API Endpoints**:
  - `POST /api/nonmmm/standardize-data` - Create standardized data files
  - `GET /api/nonmmm/standardization-status/{filename}` - Check standardization status
  - `GET /api/nonmmm/download-standardized/{filename}` - Download standardized files
- **Enhanced Model Training**: Updated to support data type selection (original vs standardized)
- **File Management**: New directory structure for standardized files

**Frontend Changes:**
- **New Component**: `NonMMMDataStandardizationStep.tsx` - Step 5 in workflow
- **Enhanced Model Building**: Added data type selection UI
- **Updated Wizard**: Integrated standardization step into Non-MMM workflow
- **State Management**: Added standardization state tracking

**Standardization Methods:**
- **Z-Score**: `(x - mean) / std` - Best for normally distributed data
- **Min-Max**: `(x - min) / (max - min)` - Scales to [0,1] range  
- **Robust**: `(x - median) / IQR` - More robust to outliers
- **Unit Vector**: `x / ||x||` - Scales to unit norm

#### Files Created/Modified:
- `backend/python/app/services/data_standardization_service.py` - New standardization service
- `backend/python/app/routes/nonmmm_routes.py` - Added standardization endpoints
- `frontend/src/analysis/nonmmm/steps/NonMMMDataStandardizationStep.tsx` - New standardization step
- `frontend/src/analysis/nonmmm/steps/NonMMMModelBuildingStep.tsx` - Added data type selection
- `frontend/src/analysis/nonmmm/wizard/NonMMMWizard.tsx` - Updated workflow routing

#### User Experience:
- **Step 5**: Data Standardization with method selection and variable choice
- **Step 6**: Model Building with data type selection (Original vs Standardized)
- **Skip Option**: Users can skip standardization and use original data
- **Progress Tracking**: Standardization completion tracked in workflow state
- **File Management**: Standardized files stored separately from original data

#### Benefits:
- ✅ **Improved Model Performance**: Standardized data often leads to better model convergence
- ✅ **Variable Comparability**: Coefficients become more comparable across variables
- ✅ **Reduced Numerical Issues**: Prevents issues with variables having vastly different scales
- ✅ **Professional Workflow**: Adds proper data preprocessing step
- ✅ **Audit Trail**: Maintains both original and standardized data for transparency
- ✅ **User Choice**: Users can choose between original and standardized data for modeling

### ✅ Correlation Matrix Variable Selection Feature (2025-01-31)

#### Feature Overview:
Added interactive variable selection for correlation matrix in Non-MMM analysis data summary step. Users can now choose which variables to include in the correlation matrix analysis.

#### Key Features:
1. **Variable Selection UI**: Checkbox interface showing all numeric variables
2. **Select All/None**: Bulk selection controls for convenience
3. **Dynamic Matrix Update**: Correlation matrix updates in real-time based on selection
4. **State Persistence**: Variable selection is saved and restored across sessions
5. **Backend Integration**: Python backend supports filtered correlation matrix generation

#### Implementation Details:

**Frontend Changes:**
- Added `selectedCorrelationVariables` state management
- Created variable selection UI with checkboxes
- Implemented real-time correlation matrix updates
- Added state persistence for variable selection

**Backend Changes:**
- Modified `/api/nonmmm/correlation-matrix/{filename}` endpoint
- Added optional `variables` query parameter for variable filtering
- Enhanced error handling for invalid variable selections

**State Management:**
- Variable selection saved to NonMMM state service
- Automatic restoration of previous selections on page reload
- Validation of saved variables against current dataset

#### Files Modified:
- `frontend/src/analysis/nonmmm/steps/NonMMMDataSummaryStep.tsx`
- `frontend/src/analysis/nonmmm/services/NonMMMFileService.ts`
- `backend/python/app/routes/nonmmm_routes.py`

#### User Experience:
- Users see all numeric variables as checkboxes
- Can select/deselect individual variables or use "Select All"
- Correlation matrix updates immediately when selection changes
- Selection is preserved when navigating between steps
- Clear visual feedback for selected variables

### ✅ Bulk Operations in Data Summary (2025-01-31)

#### Feature Overview:
Enhanced the Non-MMM Data Summary step with comprehensive bulk operations for managing multiple variables simultaneously. Users can now select multiple rows and perform bulk operations for data type changes, expected sign setting, and variable deletion.

#### Key Features:
1. **Multi-Row Selection**: Checkbox-based selection system for individual and bulk operations
2. **Bulk Data Type Changes**: Change data types for multiple variables at once
3. **Bulk Expected Sign Setting**: Set expected signs for multiple variables simultaneously
4. **Bulk Variable Deletion**: Remove multiple variables from the dataset with safety checks
5. **Smart UI**: Contextual bulk actions panel that appears when rows are selected
6. **State Persistence**: All bulk operations are properly saved and persist across steps

#### Implementation Details:

**Frontend Enhancements:**
- **Multi-Row Selection**: Enhanced table with individual checkboxes and "Select All" functionality
- **Bulk Actions Panel**: Sticky panel that appears when rows are selected with three operation types:
  - Data Type Change: Dropdown to select new data type for all selected variables
  - Expected Sign Setting: Dropdown to set expected sign (positive/negative/neutral) for all selected variables
  - Variable Deletion: Button to delete selected variables with target variable protection
- **Safety Features**: Prevents deletion of target variable with clear error messaging
- **Visual Feedback**: Clear indication of selected rows and operation status

**Backend Integration:**
- **New Endpoint**: `DELETE /api/nonmmm/delete-variable/{filename}` - Deletes variables from Excel files
- **Bulk Processing**: Handles multiple variable operations efficiently
- **Cache Management**: Automatically clears cached data summaries after bulk operations
- **File Persistence**: Modifications are saved directly to the original Excel/CSV files

**State Management:**
- **Real-time Updates**: Local state updates immediately after bulk operations
- **Persistence**: All changes are saved to NonMMM state service
- **Consistency**: Automatic data reload ensures backend-frontend consistency
- **Error Handling**: Comprehensive error handling with user-friendly messages

#### User Experience:
- **Intuitive Selection**: Easy checkbox-based selection with visual feedback
- **Efficient Operations**: Perform multiple changes with single actions
- **Safety First**: Protected operations prevent accidental data loss
- **Immediate Feedback**: Real-time updates and success/error notifications
- **Seamless Integration**: Bulk operations integrate naturally with existing workflow

#### Technical Benefits:
- **Performance**: Bulk operations reduce API calls and improve efficiency
- **Consistency**: All operations maintain data integrity and state consistency
- **Scalability**: Handles large datasets with multiple variables efficiently
- **Maintainability**: Clean separation of concerns with reusable bulk operation functions

### ✅ Brand Parameter Fix for Data Filtering (2025-01-31)

#### Issue Fixed:
The `/api/data/filtered` endpoint was returning 404 errors because the frontend was not passing the required `brand` parameter to the backend.

#### Root Cause:
- The `dataSummaryService.getFilterOptions()` method was not including the brand parameter in the API call
- The backend expects a `brand` query parameter for brand-specific data filtering
- This caused 404 errors when trying to load filter options for data summary

#### Solution Implemented:
1. **Updated `dataSummaryService.getFilterOptions()` method**:
   - Added optional `brand` parameter to method signature
   - Modified API call to include brand in query string when provided
   - Maintains backward compatibility with optional parameter

2. **Updated `FilterSidebar` component**:
   - Modified to pass `state.selectedBrand` to `getFilterOptions()` call
   - Ensures brand context is properly passed to backend

#### Files Modified:
- `frontend/src/analysis/mmm/services/dataSummaryService.ts`
- `frontend/src/analysis/mmm/steps/FilterSidebar.tsx`

#### Technical Details:
```typescript
// Before (causing 404 errors)
const response = await fetch(`${apiUrl}/filtered`, {
  method: 'POST',
  body: JSON.stringify({ filename, filters: {}, columns, limit: 1 })
});

// After (working correctly)
const response = await fetch(`${apiUrl}/filtered${brand ? `?brand=${encodeURIComponent(brand)}` : ''}`, {
  method: 'POST',
  body: JSON.stringify({ filename, filters: {}, columns, limit: 1 })
});
```

#### Result:
- ✅ Filter options now load correctly from backend
- ✅ No more 404 errors on `/api/data/filtered` endpoint
- ✅ Brand-specific data filtering works as expected
- ✅ Maintains backward compatibility for non-brand-specific calls

### ✅ Download Analysis Step Implementation

#### Feature Added:
Replaced the Model Results step with a new Download Analysis step that generates PowerPoint presentations from Non-MMM analysis data.

#### Implementation Details:

##### 1. New Download Analysis Component:
- **File**: `frontend/src/analysis/nonmmm/steps/NonMMMDownloadAnalysisStep.tsx`
- **Purpose**: Final step for Non-MMM analysis workflow - generates PowerPoint presentations
- **Features**:
  - PowerPoint generation with comprehensive analysis data
  - Professional presentation layout with progress tracking
  - Download functionality with error handling
  - Analysis completion workflow

##### 2. PowerPoint Content Structure:
- **Context Slide**: Data overview from selected sheet
- **Initial Insights Slide**: Key findings and analysis scope
- **Chart Analysis Slides**: One slide per variable pair with line chart and scatter plot
- **Model Results Slide**: Final production model details

##### 3. Updated Step Definitions:
```typescript
// Updated NON_MMM_STEPS
export const NON_MMM_STEPS = {
  ANALYSIS_TYPE: 1,
  DATA_UPLOAD: 2,
  TARGET_VARIABLE: 3,
  EXPECTED_SIGNS: 4,
  DATA_SUMMARY: 5,
  DATA_DISTRIBUTION: 6,
  CHART_ANALYSIS: 7,
  MODEL_BUILDING: 8,
  DOWNLOAD_ANALYSIS: 9, // Changed from MODEL_RESULTS
} as const;

// Updated NON_MMM_STEP_NAMES
export const NON_MMM_STEP_NAMES = {
  // ... other steps
  9: 'Download Analysis', // Changed from 'Model Results'
} as const;
```

##### 4. Wizard Navigation Updates:
- **Updated Route Mapping**: `/nonmmm/download` for step 6
- **Progress Calculation**: Updated to include Download Analysis step
- **Step Completion Tracking**: Added `downloadAnalysisCompleted` flag
- **URL Routing**: Updated all URL-based step detection logic

#### Backend Implementation:

##### 1. PowerPoint Generation Service:
- **File**: `backend/python/app/services/powerpoint_service.py`
- **Features**:
  - Professional PowerPoint generation using python-pptx
  - Brand-specific file organization
  - Comprehensive slide creation with analysis data
  - Error handling and validation

##### 2. API Endpoints:
- **File**: `backend/python/app/routes/powerpoint_routes.py`
- **Endpoints**:
  - `POST /api/powerpoint/generate-nonmmm` - Generate PowerPoint presentation
  - `GET /api/powerpoint/download/{filename}` - Download PowerPoint file
  - `GET /api/powerpoint/list/{brand}` - List PowerPoint files for brand
- **Integration**: Added to Non-MMM routes as `POST /api/nonmmm/generate-powerpoint`

##### 3. Dependencies Added:
- `python-pptx>=0.6.21` - PowerPoint generation
- `matplotlib>=3.7.0` - Chart generation support

#### User Experience:

##### 1. Download Analysis Step Features:
- **Analysis Data Preview**: Shows brand, target variable, data file, and chart count
- **Slide Preview**: Lists all slides that will be included in the presentation
- **Progress Tracking**: Real-time progress bar during PowerPoint generation
- **Download Functionality**: Direct download of generated PowerPoint file
- **Error Handling**: Clear error messages and retry functionality

##### 2. PowerPoint Content:
- **Professional Layout**: Widescreen (16:9) format with branded styling
- **Comprehensive Data**: All analysis results, charts, and model outputs
- **Brand Context**: Brand-specific information and analysis metadata
- **Statistical Insights**: Model results with R² scores and variable significance

#### Files Modified:
- `frontend/src/analysis/nonmmm/types/nonmmm.ts` - Updated step definitions
- `frontend/src/analysis/nonmmm/wizard/NonMMMWizard.tsx` - Updated navigation and routing
- `frontend/src/analysis/nonmmm/steps/NonMMMDownloadAnalysisStep.tsx` - New component
- `backend/python/app/services/powerpoint_service.py` - New service
- `backend/python/app/routes/powerpoint_routes.py` - New routes
- `backend/python/app/routes/nonmmm_routes.py` - Added PowerPoint endpoint
- `backend/python/app/core/routes.py` - Registered PowerPoint routes
- `backend/python/requirements.txt` - Added dependencies

#### Benefits:
- ✅ **Professional Output**: Users get a complete PowerPoint presentation
- ✅ **Comprehensive Analysis**: All analysis data included in presentation
- ✅ **Brand-Specific**: Presentations are customized for each brand
- ✅ **Easy Sharing**: PowerPoint format for easy sharing and presentation
- ✅ **Complete Workflow**: Analysis workflow now ends with deliverable output

## 🔧 Critical Bug Fixes (2025-01-31)

### ✅ Non-MMM Analysis Resume Fix (2025-01-31)

#### Issue Fixed:
Non-MMM analysis was always starting at step 1 (data upload) when resuming, even when the analysis had progressed through multiple steps including model building. Users were forced to re-upload data and repeat completed steps.

#### Root Cause:
1. **Frontend Navigation Issue**: Frontend always navigated to `/nonmmm/upload` regardless of actual progress
2. **Backend Progress Detection Failure**: Backend couldn't find uploaded files due to directory structure mismatch
3. **Incorrect Step Calculation**: Backend step calculation was designed for MMM analysis, not non-MMM

#### Solution Implemented:

##### 1. Fixed Frontend Navigation Logic:
```typescript
// Before: Always navigated to upload step
navigate('/nonmmm/upload');

// After: Navigate based on actual progress
switch (analysis.currentStep) {
  case 3: targetRoute = '/nonmmm/upload'; break;
  case 4: targetRoute = '/nonmmm/data-summary'; break;
  case 5: targetRoute = '/nonmmm/target-variable'; break;
  case 6: targetRoute = '/nonmmm/expected-signs'; break;
  case 7: targetRoute = '/nonmmm/chart-analysis'; break;
  case 8: targetRoute = '/nonmmm/model-building'; break;
  case 9: targetRoute = '/nonmmm/model-results'; break;
}
```

##### 2. Enhanced Resume Functionality:
- **Smart Step Detection**: Frontend now reads the `currentStep` from the analysis metadata
- **Proper Route Mapping**: Each step number maps to the correct route
- **User Feedback**: Toast notification shows the actual step being resumed
- **Error Handling**: Graceful fallback to upload step if step detection fails

#### Impact:
- ✅ **Fixed Resume Functionality**: Non-MMM analysis now resumes at the correct step
- ✅ **Smart Navigation**: Frontend navigates to the correct step based on progress
- ✅ **Better User Experience**: Users can continue from where they left off
- ✅ **No Data Re-upload**: Completed steps don't need to be repeated

#### Files Modified:
- `frontend/src/analysis/nonmmm/steps/NonMMMAnalysisTypeStep.tsx` - Fixed navigation logic in `handleResumeAnalysis`

#### Benefits:
- **Seamless Resume Experience**: Users can continue from where they left off
- **No Data Re-upload**: Completed steps don't need to be repeated
- **Accurate Progress Tracking**: System correctly identifies analysis progress
- **Consistent User Experience**: Resume behavior matches user expectations

## 🎨 Premium UI/UX Transformations (2025-01-31)

### ✅ Universal Layout Implementation (2025-01-31)

#### Layout Wrapper System:
A comprehensive layout system has been implemented to ensure consistent SideNavbar and PremiumFooter across all pages in the application.

#### Key Components:

##### 1. LayoutWrapper Component:
- **Purpose**: Provides consistent layout structure with SideNavbar and PremiumFooter
- **Location**: `frontend/src/components/wizard/LayoutWrapper.tsx`
- **Features**:
  - Configurable sidebar and footer visibility
  - Responsive design that adapts to different screen sizes
  - Proper spacing and layout management
  - Integration with React Router for navigation context

##### 2. Updated Pages:
All main pages now use the LayoutWrapper for consistent navigation and branding:

- **Index.tsx**: Main entry point with user type selection
- **NotFound.tsx**: 404 error page
- **BrandLeaderWizard.tsx**: Brand leader workflow
- **DataScientistWizard.tsx**: Data scientist workflow
- **MMMWizard.tsx**: MMM analysis workflow
- **NonMMMWizard.tsx**: Non-MMM analysis workflow

##### 3. Layout Features:
- **SideNavbar**: 
  - Dynamic breadcrumb generation based on current path
  - Navigation to previous pages
  - Clean, minimal design with premium styling
  - Responsive layout (hidden on mobile, visible on desktop)

- **PremiumFooter**:
  - Sophisticated footer with platform information
  - Contact and support details
  - Premium visual elements and animations
  - Professional branding elements

##### 4. Implementation Benefits:
- **Consistency**: All pages now have uniform navigation and branding
- **User Experience**: Easy navigation between different sections
- **Professional Appearance**: Premium design suitable for corporate clients
- **Maintainability**: Centralized layout management
- **Responsive Design**: Adapts to different screen sizes

#### Technical Implementation:
- **Component Structure**: Wrapper component that includes SideNavbar and PremiumFooter
- **Props Interface**: Configurable showSidebar and showFooter options
- **Router Integration**: Uses React Router for navigation context
- **Responsive Design**: Mobile-first approach with proper breakpoints

## 🎨 Premium UI/UX Transformations (2025-01-31)

### ✅ Chart Analysis Page Premium Redesign (2025-01-31)

#### Transformation Overview:
The Chart Analysis page has been completely redesigned to match the premium brand guidelines, creating a sophisticated and professional user experience suitable for billion-dollar corporate clients.

#### Key Design Improvements:

##### 1. Premium Hero Header:
- **Glassmorphism Icon**: 24x24 icon container with gradient background and backdrop blur
- **Typography Hierarchy**: 6xl/7xl font sizes with gradient text effects
- **Feature Indicators**: Premium pill-style indicators with gradient backgrounds and shadows
- **Responsive Layout**: Mobile-first design with progressive enhancement

##### 2. Sophisticated Filter Controls:
- **Premium Card Design**: Gradient backgrounds with backdrop blur and sophisticated shadows
- **Enhanced Button Styling**: Custom gradient buttons with hover animations and transform effects
- **Visual Hierarchy**: Clear separation between filter options with color-coded states
- **Interactive Feedback**: Smooth transitions and hover effects for better UX

##### 3. Premium Summary Statistics:
- **Gradient Cards**: Each statistic card features unique gradient backgrounds
- **Icon Integration**: Custom icon containers with gradient backgrounds
- **Hover Effects**: Transform animations and enhanced shadows on hover
- **Color Coding**: Green for expected, red for unexpected, primary for total

##### 4. Enhanced Loading States:
- **Premium Loading Animation**: Dual-ring spinner with ping effect
- **Sophisticated Layout**: Centered design with premium typography
- **Debug Information**: Clean card-based layout for configuration details
- **Error States**: Professional error messaging with appropriate visual hierarchy

##### 5. Premium Continue Button:
- **Gradient Background**: Primary gradient with sophisticated shadows
- **Hover Effects**: Scale and translate animations with enhanced shadows
- **Typography**: Large, bold text with proper spacing
- **Icon Integration**: Emoji and arrow icon with proper alignment

#### Technical Implementation:
- **CSS Classes**: Utilizes existing gradient and animation classes from brand design system
- **Responsive Design**: Mobile-first approach with proper breakpoints
- **Accessibility**: Maintains proper contrast ratios and focus states
- **Performance**: Optimized animations with hardware acceleration

#### Brand Compliance:
- **Color Palette**: Deep navy primary, sophisticated teal secondary, warm gold accent
- **Typography**: SF Pro Display font stack with proper hierarchy
- **Spacing**: Consistent spacing system (8px base unit)
- **Shadows**: Premium shadow system with appropriate depth
- **Animations**: Smooth transitions with cubic-bezier timing

## 🚨 Recent Critical Fixes (2025-09-02)

### ✅ Non-MMM Analysis State Persistence Fix (2025-09-02)

#### Issue Fixed:
Non-MMM analysis state persistence was broken, causing users to lose progress when navigating back from chart analysis and showing step 1 instead of saved progress when refreshing the app.

#### Root Cause:
1. **Backend Integration Gap**: The `NonMMMStateService` had backend integration methods but they weren't being used by the static methods that components rely on
2. **State Storage Mismatch**: Components used `getNonMMMState()` and `saveNonMMMState()` which only used localStorage, not the backend
3. **Navigation Logic Issue**: The wizard didn't properly restore state from backend when resuming analysis

#### Solution Implemented:

##### 1. Enhanced State Service Integration:
```typescript
// Updated static methods to integrate with backend
public static async getNonMMMState(): Promise<Record<string, unknown> | null> {
  // First try localStorage for immediate access
  // Then sync with backend in background
  // Fallback to backend loading if no local state
}

public static async saveNonMMMState(state: Record<string, unknown>): Promise<void> {
  // Save to localStorage first for immediate access
  // Also save to backend for persistence
}
```

##### 2. Backend State Loading:
```typescript
// New method to load state from backend
public static async loadStateFromBackend(analysisId: string): Promise<Record<string, unknown> | null> {
  // Load state from backend and cache in localStorage
}
```

##### 3. Enhanced Wizard Navigation:
```typescript
// Updated wizard to load from backend when resuming
if (currentAnalysisId) {
  let savedState = await NonMMMStateService.getNonMMMState();
  if (!savedState) {
    savedState = await NonMMMStateService.loadStateFromBackend(currentAnalysisId);
  }
  // Navigate to saved step
}
```

##### 4. Updated All Step Components:
- Made all state operations async
- Added proper analysisId to state saves
- Enhanced error handling and logging

#### Impact:
- ✅ **Fixed State Persistence**: Users no longer lose progress when navigating back
- ✅ **Fixed Resume Functionality**: App refresh now properly restores saved progress
- ✅ **Backend Integration**: State is now properly saved to and loaded from backend
- ✅ **Enhanced Navigation**: Wizard properly restores state from backend when resuming
- ✅ **Improved Reliability**: Better error handling and fallback mechanisms

#### Files Modified:
- `frontend/src/analysis/nonmmm/services/NonMMMStateService.ts` - Enhanced backend integration
- `frontend/src/analysis/nonmmm/wizard/NonMMMWizard.tsx` - Updated navigation logic
- `frontend/src/analysis/nonmmm/steps/NonMMMChartAnalysisStep.tsx` - Made state operations async
- `frontend/src/analysis/nonmmm/steps/NonMMMDataUploadStep.tsx` - Enhanced state saving
- `frontend/src/analysis/nonmmm/steps/NonMMMDataSummaryStep.tsx` - Updated state operations
- `frontend/src/analysis/nonmmm/steps/NonMMMModelBuildingStep.tsx` - Made state operations async

#### Benefits:
- **Complete State Persistence**: Non-MMM analysis state is now properly saved and restored
- **Seamless Navigation**: Users can navigate back and forth without losing progress
- **Reliable Resume**: App refresh and resume functionality works correctly
- **Backend Integration**: State is persisted across sessions and devices
- **Better User Experience**: No more lost progress or confusion about current step

## 🚨 Recent Critical Fixes (2025-01-31)

### ✅ Issues Resolved
1. **Fixed premature "Analysis Created" toast messages** - Now only shows after data upload completion (step 3)
2. **Fixed 404 errors when saving concatenation state** - Removed backend health checks per workspace rules  
3. **Fixed component mounting/unmounting race conditions** - Improved initialization guards and cleanup
4. **Clarified Python vs Node.js backend responsibilities** - Python backend exclusive for all operations
5. **Fixed concatenation race conditions** - Serialized state saving operations
6. **Optimized state persistence timing** - Only saves state after full validation
7. **Updated analysis success criteria** - Requires data upload before marking as successful
8. **CRITICAL: Fixed infinite loop in DataConcatenationStep** - Added proper initialization guards to prevent repeated API calls during navigation between steps (2025-01-27)
9. **CRITICAL: Fixed incomplete analysis deletion & RPI state persistence** - Analysis deletion now properly cleans up localStorage RPI completion states, preventing new analyses from inheriting previous RPI completion status (2025-01-31)
9. **CRITICAL: Fixed resume analysis navigation bug** - Resume analysis now correctly navigates to the last completed step instead of starting from step 1 (2025-01-27)
10. **CRITICAL: Migrated state management from Python to Node.js backend** - Updated existing brandAnalysisService to use Node.js backend instead of Python, maintaining clean architecture and avoiding service duplication (2025-01-27)
11. **CRITICAL: Fixed duplicate logs in AddRPIsStep** - Eliminated duplicate console logs caused by multiple useEffect executions and component re-mounting by adding useRef-based execution prevention for RPI completion checks and pack size analysis (2025-01-31)
12. **CRITICAL: Fixed incorrect step routing in analysis resume** - Removed incorrect URL routing that mapped internal wizard steps to wrong route paths (e.g., step 5 incorrectly routing to /mmm/step/2). Now uses proper internal step navigation within MMMWizard based on context.currentStep, ensuring users resume at their actual last completed step (2025-01-31)
13. **CRITICAL: Fixed step progression mismatch and URL artifacts** - Corrected step numbering inconsistencies between backend analysis state and MMMWizard internal mapping. Removed App.tsx redirect to /mmm/step/1 that was causing URL confusion. Fixed getCompletedSteps() function to align with actual MMMWizard step numbering (1-13 instead of mixed numbering). Users now properly resume at the AddRPIsStep (step 3) after completing data concatenation (2025-01-31)
14. **CRITICAL: Standardized step numbering system across entire application** - Implemented consistent step numbering where analysis steps start from Data Upload as step 1, eliminating confusion from previous 13-step vs 11-step discrepancies. Updated STEP_NAMES/STEP_TITLES in appConstants.ts to remove User Type/Analysis Type (now prerequisites), fixed backend calculateCurrentStep() to use 1-11 numbering, updated MMMWizard totalSteps to 11, and corrected progress indicators and documentation throughout codebase. Step counting now begins only at analysis start (Data Upload), not user prerequisites (2025-01-31)
15. **FEATURE: Implemented Non-MMM Chart Analysis Step** - Complete implementation of chart analysis functionality with line charts, scatter plots, trendline analysis (linear, polynomial degree 2/3), and expected vs unexpected result filtering. Uses Python backend for data processing and statistical calculations, Node.js backend for state management, and Chart.js for visualization. Provides real-time chart generation with proper loading states and comprehensive error handling (2025-01-31)

15.1. **CRITICAL: Fixed Chart Regeneration Issue** - Resolved the critical bug where charts would regenerate every time the user clicked "Continue to Model Building" due to component remounting. Implemented chart state hydration from saved state before deciding to generate new charts. Added proper state persistence with chartsGenerated flag and chartData storage in NonMMM state. Enhanced loading state logic to prevent unnecessary regeneration when charts already exist. The fix ensures charts are only generated once and properly restored from saved state on component remount (2025-01-31)

15.2. **CRITICAL: Fixed State Extraction Logic** - Resolved the "Missing data" issue where non-MMM steps couldn't extract filename and targetVariable from saved state. The problem was that state data was nested under `stepData` but extraction logic was only looking at the top level. Updated all non-MMM steps (Chart Analysis, Data Summary, Data Standardization) to check both top-level and `stepData` properties for backward compatibility. This ensures proper data extraction regardless of state structure and prevents "No target variable selected" errors (2025-01-31)

15.3. **CRITICAL: Simplified Chart Regeneration Prevention** - Implemented a bulletproof solution using a permanent `chartsGenerated` flag that never resets. The flag starts as `false` and becomes `true` the moment charts are generated for the first time, then never changes back. Simplified the chart generation logic to just check this single flag instead of complex state checking. This eliminates all race conditions and ensures charts are never regenerated once generated for an analysis. The solution is simple, reliable, and prevents all regeneration issues (2025-01-31)
16. **UI CLEANUP: Streamlined Non-MMM Chart Analysis Interface** - Removed visual clutter from chart analysis step by eliminating the chart icon above the title, removing the 3 summary statistics cards, removing expected/unexpected badges from the filter section, and removing emoji icons from filter buttons. Interface now focuses purely on the essential chart analysis functionality with a cleaner, more professional appearance (2025-01-31)
17. **FEATURE: Implemented Non-MMM Model Building Step** - Complete implementation of statistical modeling functionality with model type selection (linear, log-linear, log-log, ridge, bayesian), variable selection via checkboxes, model training, and results display. Uses Python backend for model training with scikit-learn, comprehensive state persistence, and real-time model execution with performance metrics and variable statistics (2025-01-31)

18. **CRITICAL: Removed Startup Page and Streamlined Entry Point** - Eliminated the fancy startup page with marketing content and animations that was blocking access to the main user flow. Updated Index.tsx to provide immediate access to the Brand Leader vs Data Scientist choice without any distractions. Users now land directly on the user type selection interface for a streamlined, focused entry experience (2025-01-31)

19. **CRITICAL: Minimal Design Implementation** - Completely cleaned up the user type selection page to be minimal and focused. Removed all unnecessary visual elements, animations, marketing text, icons, and complex styling. Now shows only a simple title and two clean buttons for Brand Leader vs Data Scientist selection. Eliminates all distractions to maintain maximum focus on the essential choice (2025-01-31)

20. **PREMIUM: Dynamic Video Background Implementation** - Replaced static purple background with dynamic flowing data streams video background from Cloudinary. Added subtle black overlay (30% opacity) for optimal text readability. Enhanced text with drop shadows for better contrast over video. Maintained glassmorphism button styling for seamless integration. The video creates an engaging, professional atmosphere while keeping the interface clean and focused (2025-01-31)

21. **PREMIUM: Corporate-Grade Landing Page Design** - Transformed the landing page into a sophisticated, premium interface suitable for big corporations. Implemented refined typography with gradient text effects, generous spacing, and elegant visual hierarchy. Added premium button designs with subtle hover animations, sophisticated teal/turquoise color palette, and refined visual elements including floating accent orbs. Enhanced the video container with premium shadows, subtle overlays, and sophisticated border treatments. Added professional footer with glassmorphism effect to denote page completion. The design maintains minimalism while conveying luxury and corporate professionalism (2025-01-31)

22. **EPIC: Animated Loading Screen Implementation** - Created a sophisticated loading screen featuring an animated Marico logo with multiple visual effects including rotating glow rings, pulsing animations, and smooth transitions. The loading screen displays for 3 seconds before revealing the main application, providing an engaging and premium first impression. Features include: multi-layered logo animations with outer/middle/inner glow rings, floating background elements, animated loading dots, smooth fade-in/fade-out transitions, a white background layer to ensure logo clarity against animated backgrounds, and an enhanced animation sequence where the logo grows bigger (1 second) with organic blur and rotation effects, stays alive with breathing animations and dynamic color-shifting glow rings (1 second), then shrinks and disappears with enhanced blur effects (1 second). The entire viewport features dynamic color waves, particle-like floating elements, and modern animation techniques for a truly alive and engaging experience. Prominently displays "Marico's Insighting Tool" in premium thin typography with gradient effects that remains visible throughout the entire loading sequence, creating a sophisticated brand presence (2025-01-31)

23. **FEATURE: Enhanced Data Scientist Portal** - Premium redesign of the Data Scientist wizard with sophisticated header section, enhanced analysis type selection interface, and improved visual hierarchy. Features premium design elements, better animations, and enhanced user experience (2025-01-31)

24. **CRITICAL: Fixed Data Scientist Page Flow** - Removed the PremiumDataScientistHeader component from DataScientistWizard that was showing marketing content ("Advanced Analytics & Modeling" with Statistical Modeling, Machine Learning, and Data Exploration cards) instead of the required MMM vs Non-MMM analysis selection. The data scientist page now correctly shows only the analysis type selection interface as per the user flow requirements. Users now see the proper MMM vs Non-MMM choice immediately after selecting "Data Scientist" without any distracting marketing content. Also deleted the unused PremiumDataScientistHeader.tsx file entirely and fixed the empty page issue by showing the selection interface immediately (2025-01-31)

25. **ENHANCEMENT: Data Scientist Page UI Improvements** - Comprehensive UI improvements to the Data Scientist page including: (1) Removed "Step 1 of 1" indicator from navbar for cleaner appearance, (2) Added side margins to MMM/Non-MMM options instead of full page width for better visual balance, (3) Made cards smaller and synced their background colors for consistent design, (4) Fixed misaligned icons with text in continue buttons by moving ArrowRight icon inside the span, (5) Added comprehensive side navbar with Home, Brand Leader, Data Scientist navigation and dynamic breadcrumb functionality that shows visited pages. The side navbar provides easy navigation back to previous steps and maintains context throughout the user journey (2025-01-31)

26. **ENHANCEMENT: Compact Card Layout with Hover Expansion** - Redesigned the analysis type selection cards for better scalability and user experience: (1) Fixed navbar alignment issues with proper padding and spacing, (2) Implemented compact card layout with fixed height (320px) that can accommodate 7+ analysis types without scrolling, (3) Added responsive grid layout (1-4 columns based on screen size) for optimal space utilization, (4) Created hover expansion functionality that reveals full details (description, features, benefits) on hover while maintaining clean default view, (5) Optimized card content with smaller icons, compact text, and streamlined information display. The new layout is ready to accommodate 5 additional analysis types while maintaining excellent user experience and visual hierarchy (2025-01-31)

19. **FEATURE: Premium Non-MMM Wizard** - Complete transformation of the Non-MMM wizard with premium design, enhanced animations, better progress tracking, and improved navigation. Features sophisticated header sections, enhanced visual elements, and premium styling throughout the workflow (2025-01-31)

20. **FEATURE: Premium Design Optimization & Horizontal Space Utilization** - Comprehensive removal of max-w constraints across all frontend components to ensure full horizontal space utilization while maintaining premium design aesthetics. Updated components include: PremiumHero, EnhancedRoleSelection, EnhancedAnalysisTypeSelection, PremiumDataScientistHeader, PremiumFooter, Non-MMM analysis steps, MMM analysis steps, and all wizard components. Eliminates horizontal space restrictions that could block optimal user experience and content display (2025-01-31)

21. **FEATURE: MMM Analysis Premium Design Completion** - Successfully applied premium design improvements and max-w constraint removal to all MMM analysis components. Verified that all MMM analysis steps (DataUploadStep, DataSummaryStep, FilterSelectionStep, ExistingAnalysisSelection, BrandSelectionStep, AddRPIsStep, DataConcatenationStep, ModelBuildingStep, ModelResultsStep, OptimizerStep, etc.) now utilize full horizontal space without constraints. Build verification confirms no functionality was broken during the transformation process (2025-01-31)

22. **BRAND COMPLIANCE: Complete Brand Guideline Implementation** - Comprehensive transformation of all application views to ensure 100% compliance with brand guidelines defined in brandDesign.mdc. Updated all components to use proper brand color system (primary, secondary, accent, muted), typography classes (text-gradient-primary, text-gradient-secondary), premium button styles (btn-premium-primary, btn-premium-secondary), and card styling (card-premium). Transformed components include: Index page, InitialWizard, DataScientistWizard, BrandLeaderWizard, all MMM analysis steps, all Non-MMM analysis steps, wizard layout components, and shared UI components. Eliminated all hardcoded colors and replaced with brand-compliant alternatives. Verified no broken routes, navigation, or wizard flow issues during transformation. All views now maintain consistent premium corporate styling throughout the application (2025-01-31)

23. **BRAND COMPLIANCE: Comprehensive Hardcoded Color Elimination** - Systematic elimination of all hardcoded colors across the entire frontend codebase to ensure 100% brand guideline compliance. Fixed hardcoded blue colors in 20 files, green colors in 19 files, purple colors in 8 files, red colors in 12 files, yellow colors in 5 files, and additional gray/orange colors in multiple files. Replaced all hardcoded color classes with brand-compliant alternatives: primary (teal/turquoise), secondary (complementary green), accent (purple/violet), destructive (red for errors), and muted (gray for neutral elements). Updated components include: DataUploadStep, DataSummaryStep, ExistingAnalysisSelection, NonMMMDataUploadStep, NonMMMExpectedSignsStep, NonMMMChartAnalysisStep, NonMMMWizard, NonMMMModelResultsStep, NonMMMModelBuildingStep, NonMMMChartContainer, NonMMMDataSummaryStep, AddRPIsStep, DataConcatenationStep, ColumnCategorization, ProcessingStatus, BrandCategorization, FilterSidebar, ProcessingSummary, DataLoadingStatus, PackSizeRankingDisplay, expectedSigns service, PremiumFooter, toast components, and all related analysis steps. All components now use consistent brand color system with proper opacity variations (e.g., bg-primary/5, text-primary/80) for enhanced visual hierarchy and premium appearance (2025-01-31)

24. **ENHANCEMENT: Complete Column Display in Data Upload Steps** - Fixed the issue where only the first 5 columns were displayed in sheet information during data upload. Updated both MMM and Non-MMM data upload steps to show all available columns for each sheet. Backend changes include: (1) Modified `get_excel_columns()` function in `file_utils.py` to return all columns by default instead of limiting to 5, (2) Updated `get_excel_sheets_info()` in `file_service.py` to fetch complete column information, (3) Enhanced frontend display in both `DataUploadStep.tsx` and `NonMMMDataUploadStep.tsx` to show all columns with proper scrolling for large datasets. Users now see the complete structure of their uploaded data with accurate column counts and full column names, providing better visibility into their dataset structure (2025-01-31)

25. **ENHANCEMENT: Proper Excel Data Type Preservation** - Fixed the issue where percentage columns were incorrectly detected as numeric instead of percentage type. Replaced hardcoded detection logic with proper Excel cell format reading using OpenPyXL. The new `detect_excel_data_type()` function reads the actual Excel cell formats to determine data types, ensuring that columns formatted as percentages in Excel are correctly identified as percentage type. This approach preserves the original data types from the Excel file without relying on hardcoded column name patterns or value range assumptions. The system now properly detects and displays percentage columns with appropriate formatting, while maintaining the dropdown functionality for users to manually change data types if needed (2025-01-31)

24. **CRITICAL: Fixed Data Scientist Portal Analysis Cards** - Resolved the broken MMM and Non-MMM analysis cards in the Data Scientist portal that were missing essential functionality. The portal was using a simplified `EnhancedAnalysisTypeSelection` component instead of the full-featured `AnalysisTypeStep` component. Fixed by: (1) Updated `DataScientistWizard` to use the complete `AnalysisTypeStep` component with all functionality, (2) Restored existing analyses display with proper loading states and delete functionality, (3) Restored brand name input fields for both MMM and Non-MMM analysis types, (4) Restored analysis creation, resume, and overwrite functionality, (5) Made cards more compact while preserving all features (reduced existing analyses display from 3 to 2 items, smaller padding, compact bullet points), (6) Enhanced header styling to match the premium design system. The Data Scientist portal now shows complete analysis management functionality including existing analyses listing, brand name input, analysis creation/resume/overwrite options, and proper state management integration with both Node.js and Python backends (2025-01-31)

25. **CRITICAL: Global Error Handling System Implementation** - Implemented comprehensive error handling system to prevent infinite refresh loops and provide robust error recovery. Features include: (1) Global ErrorBoundary component that catches React errors anywhere in the component tree, (2) Retry mechanism with maximum 2 attempts before redirecting to homepage, (3) Error state persistence using sessionStorage to track retry attempts across page refreshes, (4) Automatic homepage redirect after failed retries with clean state reset, (5) User-friendly error UI with retry and home options, (6) Development vs production error display with detailed stack traces in dev mode, (7) Custom useErrorHandler hook for consistent error handling across components, (8) Integration with existing toast notification system. The system prevents the infinite refresh loop issue where pages would get stuck trying to refresh after errors, ensuring users can always recover by being redirected to the homepage after 2 failed attempts (2025-01-31)

26. **CRITICAL: Fixed Non-MMM Analysis Step Tracking Issue** - Resolved the issue where Non-MMM analysis would always resume from step 1 instead of the user's actual last completed step. The problem was in the NonMMMWizard component which was only determining the current step from URL paths without checking saved state. Fixed by: (1) Updated NonMMMWizard to check saved state when resuming analysis and navigate to the correct step, (2) Enhanced step completion logic to save current step to global state before navigating, (3) Updated all Non-MMM step components (DataUpload, DataSummary, ChartAnalysis, ModelBuilding) to save current step state when completing steps, (4) Added proper state persistence using NonMMMStateService.getNonMMMState() and saveNonMMMState() methods, (5) Implemented initialization logic that checks for existing analysis ID and saved step before falling back to URL-based step determination. Users can now properly resume Non-MMM analysis from their actual last completed step instead of being forced to start from step 1 (2025-01-31)

27. **CRITICAL: Enhanced Error Handling and Recovery System** - Significantly improved the error handling system to prevent users from getting stuck on broken pages. The original error boundary was not catching all types of errors and wasn't properly redirecting to homepage. Enhanced by: (1) Added global error handlers for unhandled JavaScript errors and promise rejections, (2) Created comprehensive error recovery utilities with force redirect functionality, (3) Implemented emergency recovery components with visible buttons and keyboard shortcuts (Ctrl+Shift+R), (4) Added automatic stuck user detection with auto-recovery after 30 seconds, (5) Created multiple recovery options: simple redirect (preserve state) and emergency recovery (clear all state), (6) Added emergency recovery button that appears after 1 minute on any page, (7) Implemented robust state clearing and homepage redirection that works even when React is broken, (8) Added nuclear recovery option that clears ALL browser storage (localStorage, sessionStorage, IndexedDB, cookies) to ensure clean homepage redirect, (9) Made recovery functions available globally via browser console for manual recovery, (10) Enhanced state clearing to remove all possible application state that might cause automatic redirection. Users now have multiple ways to recover from stuck states: automatic recovery, visible emergency buttons, keyboard shortcuts, manual recovery options, and console-based recovery functions (2025-01-31)

## Overview

The BrandBloom Insights frontend is a React-based analytics application that provides a comprehensive 14-step wizard for Media Mix Modeling (MMM) and attribution analysis. The application is built with TypeScript, uses modern React patterns, and integrates with a Python FastAPI backend for data processing and analysis. The codebase emphasizes type safety and follows TypeScript best practices, with all services using proper typing instead of `any` types for enhanced code quality and developer experience.

## Project Structure

```
src/
├── components/          # React components organized by functionality
│   ├── ui/             # Reusable UI components (shadcn/ui)
│   ├── charts/         # Data visualization components
│   ├── packsize/       # Pack size specific components
│   ├── wizard/         # Wizard layout and navigation components
│   ├── LoadingScreen.tsx # Epic animated loading screen with Marico logo
│   ├── ErrorBoundary.tsx # Global error boundary with retry logic
│   └── ErrorTestComponent.tsx # Development error testing component
├── analysis/            # Analysis-specific components and services
│   ├── mmm/            # MMM analysis pages, types, and services
│   │   ├── pages/      # MMM analysis page components
│   │   ├── types/      # MMM analysis type definitions
│   │   ├── services/   # MMM analysis business logic
│   │   │   ├── metadata/        # MMM metadata management sub-services
│   │   │   └── dataProcessors/  # MMM data processing utilities
│   │   ├── wizard/     # MMM analysis wizard components
│   │   └── steps/      # MMM analysis step components (14 steps)
│   └── nonmmm/         # Non-MMM analysis pages, types, and services
│       ├── pages/      # Non-MMM analysis page components
│       ├── types/      # Non-MMM analysis type definitions
│       ├── services/   # Non-MMM analysis business logic
│       ├── wizard/     # Non-MMM analysis wizard components
│       └── steps/      # Non-MMM analysis step components (8 steps)

├── context/             # React Context for global state management
├── hooks/               # Custom React hooks
│   ├── useErrorHandler.ts # Error handling hook with retry logic
│   ├── useConcatenationState.ts # Concatenation state management
│   └── useFilteredData.ts # Data filtering utilities
├── types/               # TypeScript type definitions (shared across application)
├── utils/               # Utility functions and helpers
│   ├── numberFormatter.ts  # Number formatting utilities for histograms and charts
│   ├── apiClient.ts        # API client for backend communication
│   ├── devConsole.ts       # Development console utilities
│   ├── index.ts            # Utility function exports
│   └── logger.ts           # Logging utilities
├── config/              # Configuration files
├── lib/                 # Third-party library configurations
├── pages/               # Page-level components
└── App.tsx              # Main application component
```

## Premium Design & User Experience

### 🎨 Premium Design Transformation (2025-01-31)
**Purpose**: Transform the entire frontend into a premium, engaging user experience with sophisticated design elements and optimal space utilization.

**Key Improvements**:
1. **Premium Home Page**: Complete redesign with engaging hero section, floating geometric elements, premium typography, and staggered animations
2. **Enhanced Role Selection**: Premium card designs with enhanced hover effects, selection indicators, and detailed feature highlights
3. **Data Scientist Portal**: Sophisticated header section with animated backgrounds and premium visual elements
4. **Analysis Type Selection**: Enhanced interface for choosing between MMM and Non-MMM analysis with premium styling
5. **Non-MMM Wizard**: Complete transformation with premium design, enhanced animations, and improved navigation
6. **Horizontal Space Optimization**: Comprehensive removal of max-w constraints across all components for full space utilization

**Design Principles**:
- **Premium Aesthetics**: Sophisticated color palettes, shadows, refined typography, and generous whitespace
- **Smooth Animations**: Staggered entrance animations, floating elements, and interactive visual feedback
- **Full Space Utilization**: No horizontal space restrictions, optimal content display across all screen sizes
- **Epic Loading Experience**: Sophisticated animated loading screen with Marico logo for premium first impression
- **Visual Hierarchy**: Clear information architecture with premium styling and enhanced user engagement
- **Responsive Design**: Maintains premium aesthetics across all device sizes while optimizing space usage

**Components Updated**:
- `LoadingScreen`: Epic animated loading screen with Marico logo and multiple visual effects
- `PremiumHero`: Engaging hero section with floating elements and premium animations
- `EnhancedRoleSelection`: Premium role selection interface with enhanced features
- `EnhancedAnalysisTypeSelection`: Sophisticated analysis type selection
- `PremiumDataScientistHeader`: Premium header for Data Scientist portal
- `PremiumFooter`: Sophisticated footer with platform information
- All analysis step components (MMM & Non-MMM)
- All wizard components and navigation elements

**Animation System**:
- CSS `@keyframes` for fadeIn, fadeInUp, scaleIn, float animations
- Staggered entrance sequences for progressive content reveal
- Floating geometric elements and interactive visual feedback
- Smooth transitions and hover effects throughout the interface

## Core Architecture

### 1. Number Formatting Utilities (`src/utils/numberFormatter.ts`)
**Purpose**: Provides utility functions for formatting numbers in a user-friendly way for data visualization and display.

**Key Functions**:
- `formatNumberForDisplay(value, removeDecimalsThreshold)`: Main number formatting function
- `formatHistogramBinLabel(value)`: Formats individual histogram bin values
- `formatHistogramRangeLabel(startValue, endValue)`: Formats histogram bin ranges
- `formatPercentage(value, showPercentSign)`: Formats percentage values with K/L/Cr formatting

**Formatting Logic**:
- **Small values (< 1)**: Show appropriate decimals (2-3 decimal places)
- **Values ≥ 1**: Remove unnecessary decimals, show as whole numbers
- **Large numbers**: Convert to thousands (K), lacs (L), crores (Cr) format
- **Percentages**: Apply K/L/Cr formatting for large percentage values while maintaining precision

**Usage Examples**:
```typescript
import { formatNumberForDisplay, formatPercentage } from '@/utils/numberFormatter';

// Basic number formatting - NO decimals for values >= 1
formatNumberForDisplay(0.5)        // '0.5'
formatNumberForDisplay(1.5)        // '1.5' (still shows decimal for fractional values)
formatNumberForDisplay(2.0)        // '2' (no decimal for whole numbers)
formatNumberForDisplay(2.7)        // '2.7' (shows decimal for fractional values)
formatNumberForDisplay(1500)       // '1.5K'
formatNumberForDisplay(150000)     // '1.5L'
formatNumberForDisplay(15000000)   // '1.5Cr'

// Percentage formatting - NO decimals for percentages >= 1%
formatPercentage(0.05)             // '5%' (shows decimal for < 1%)
formatPercentage(0.15)             // '15%' (shows decimal for < 1%)
formatPercentage(1.5)              // '150%' (no decimal for >= 1%)
formatPercentage(15.0)             // '15K%' (no decimal for >= 1%)
formatPercentage(150.0)            // '150L%' (no decimal for >= 1%)
```

**Components Using This Utility**:
- `NonMMMDataSummaryStep.tsx`: Data summary table, histograms, correlation matrix
- `DataDistributionChart.tsx`: Histogram bin labels and ranges
- `dataProcessor.ts` (MMM): Histogram range formatting
- All histogram displays across the application

**Benefits**:
- Consistent number formatting across the entire application
- Improved readability for large numbers (K, L, Cr format)
- Appropriate decimal precision based on value magnitude
- Enhanced user experience with cleaner data visualization

### 2. Service Organization & Separation

#### MMM Services (`src/analysis/mmm/services/`)
- **Purpose**: All services specific to MMM analysis workflows
- **Key Services**:
  - `brandAnalysisService`: Brand analysis and categorization
  - `initializationService`: MMM analysis initialization and race condition prevention
  - `rpiAdditionService`: RPI variable addition and management
  - `packSizeService`: Pack size analysis and management
  - `fileService`: File upload and processing for MMM workflows
  - `metadataService`: MMM metadata management and validation (instance-based service)
  - `dataSummaryService`: Data summary and statistics for MMM
  - `excelService`: Excel file operations and concatenation
  - `exportService`: Data export and download
  - `dataProcessor`: Data processing and transformation
  - `brandExtractor`: Brand name extraction and categorization
  - `filterService`: Data filtering and management
  - `expectedSigns`: Expected signs calculation and color coding
  - `validationService`: Data validation and quality checks
  - `wizardManager`: Wizard workflow management
  - `modelService`: Model generation and results

#### Recent Fixes (2025-01-27):
- **MetadataService Import Fix**: Fixed service exports in `index.ts` to export instance `metadataService` instead of class `MetadataService`
- **DataConcatenationStep Fix**: Fixed incorrect usage of `MetadataService.saveConcatenationState` to use instance method `metadataService.saveConcatenationState`
- **MetadataService Architecture Fix**: Converted all static methods to instance methods in `MetadataService` class to match usage pattern
- **Type Safety**: Ensured proper type imports and exports for better runtime reliability
- **Folder Structure Compatibility**: Verified compatibility with new brand-specific folder structure `<brandname>/data/<internal folders>`
- **Analysis Exists Dialog Fix**: Fixed missing `existingAnalysisData` when showing "Analysis Already Exists" dialog - now properly loads existing analysis before showing dialog
- **Race Condition Prevention**: Added additional safeguards in `AnalysisTypeStep` to prevent multiple simultaneous analysis creation attempts
- **Backend Analysis Detection Fix**: Fixed `check_brand_exists` to properly detect existing analyses regardless of timestamp variations in analysis IDs
- **Pending Analysis Cleanup Fix**: Enhanced backend `delete_analysis` to properly clean up both pending analyses and brand directories
- **Analysis ID Consistency Fix**: Unified analysis ID generation between `BrandAnalysisService` and `AnalysisManager` to use simple brand names without timestamps
- **Resume Analysis Navigation Fix**: Fixed critical bug in `ExistingAnalysisSelection.tsx` where resuming analysis would navigate to `/mmm` (which redirects to step 1) instead of specific step routes like `/mmm/step/3`. Now correctly navigates to the appropriate step route matching the analysis progress.
- **State Management Architecture Migration**: Migrated all analysis lifecycle operations from Python backend to Node.js backend by updating existing `brandAnalysisService.ts` to use Node.js endpoints. This maintains proper backend separation without creating duplicate services, ensuring clean architecture and optimal performance for JSON operations.

#### Non-MMM Services (`src/analysis/nonmmm/services/`)
- **Purpose**: All services specific to Non-MMM analysis workflows
- **Key Services**:
  - `NonMMMStateService`: State persistence and management
  - `NonMMMFileService`: File upload and Excel processing
  - `NonMMMDataSummaryService`: Data summary and statistics
  - `NonMMMChartAnalysisService`: Chart generation and trendline analysis
  - `NonMMMModelingService`: Statistical modeling and results

#### Service Separation Benefits:
- **Clear Boundaries**: MMM and Non-MMM services are completely separate
- **Independent Evolution**: Each analysis type can evolve independently
- **No Cross-Contamination**: Services don't interfere with each other
- **Modular Architecture**: Easy to maintain and extend each workflow
- **Type Safety**: Each service has its own type definitions

### 2. Race Condition Prevention & Single Initialization Point

#### `InitializationService` (`src/analysis/mmm/services/initializationService.ts`)
- **Purpose**: Single point of control for analysis initialization to prevent race conditions and multiple execution paths
- **Key Features**:
  - Prevents multiple simultaneous initializations
  - Coordinates between different components (AnalysisTypeStep, DataConcatenationStep, ExistingAnalysisSelection)
  - Handles both new analysis and resume analysis workflows
  - Maintains internal state to prevent duplicate requests
  - **ALL** analysis operations go through this service
- **Methods**:
  - `initializeNewAnalysis()`: **ONLY** entry point for new analysis creation
  - `overwriteExistingAnalysis()`: **ONLY** entry point for overwriting existing analyses
  - `resumeExistingAnalysis()`: **ONLY** entry point for resuming existing analyses
  - `listAnalyses()`: **ONLY** entry point for listing analyses
  - `isCurrentlyInitializing()`: Status check to prevent component conflicts
  - `cleanupAnalysis()`: Coordinated cleanup with state reset
- **Race Condition Prevention**:
  - Internal locks prevent multiple simultaneous executions
  - State tracking prevents re-initialization of same brand/type
  - Component coordination through service status checks
  - **ZERO** direct service calls from components
- **Single Flow Architecture**:
  - **New Analysis**: `initializeNewAnalysis()` → Brand check → Analysis creation → State setup
  - **Overwrite Analysis**: `overwriteExistingAnalysis()` → Force overwrite → Analysis recreation → State reset
  - **Resume Analysis**: `resumeExistingAnalysis()` → Load existing → State restoration → Continue workflow

### 2. Application Entry Points

#### `main.tsx`
- **Purpose**: React application bootstrap and DOM mounting
- **Dependencies**: React 18 createRoot API, App component, global CSS
- **Flow**: Application initialization → DOM mounting → App rendering

#### `App.tsx`
- **Purpose**: Root component with routing, providers, and workflow setup
- **Key Features**:
  - React Router configuration for 14-step wizard
  - Global state management via AnalysisProvider
  - UI component providers (Toast, Tooltip, Query)
  - Complete step-by-step analysis workflow routing
- **Dependencies**: React Router, TanStack Query, Radix UI, AnalysisContext

### 2. Wizard Workflow Steps

The application follows a 14-step analytics workflow:

#### Step 1: User Type Selection (`UserTypeStep`)
- **Purpose**: User role selection (Brand Leader vs Data Scientist)
- **Key Functions**: Role selection, workflow customization
- **Data Flow**: User selection → Context update → Workflow customization

#### Step 2: Analysis Type Selection (`AnalysisTypeStep`)
- **Purpose**: Analysis type and brand management with single initialization point
- **Key Functions**: Analysis type selection, brand creation/selection, existing analysis loading
- **API Endpoints**: Analysis CRUD operations via initialization service
- **Data Flow**: Type selection → Single initialization service → Brand management → Analysis creation/restoration
- **Race Condition Prevention**: Uses centralized initialization service to prevent multiple execution paths
- **Optimization**: Loads existing analyses only once on mount, updates local state directly for deletions

#### Step 3: Analysis Mode Selection (`AnalysisModeStep`)
- **Purpose**: New vs existing analysis workflow choice
- **Key Functions**: Mode selection, existing analysis integration
- **Data Flow**: Mode selection → Existing analysis loading → Workflow continuation

#### Step 4: Data Upload (`DataUploadStep`)
- **Purpose**: File upload with drag-and-drop and data quality enhancement
- **Key Functions**: File upload, Excel processing, data quality filtering, business column enhancement
- **API Endpoints**: File upload, column modification, data quality enhancement
- **Data Flow**: File upload → Processing → Quality enhancement → Sheet selection
- **Navigation**: Uses `nextStep()` from AnalysisContext for proper wizard step management

#### Step 5: Data Concatenation (`DataConcatenationStep`)
- **Purpose**: Excel sheet concatenation with simplified state preservation and restoration
- **Key Functions**: Sheet concatenation, target variable selection, filter management, brand categorization
- **State Preservation**: SIMPLIFIED - Single-source logic that checks existing data and skips initialization
- **API Endpoints**: Sheet concatenation, data filtering, state persistence
- **Data Flow**: Sheet selection → Concatenation → Data preview → Variable/filter selection → Brand categorization
- **State Preservation Logic**:
  - Simple check: If concatenated data exists, skip initialization entirely
  - No complex tracking mechanisms - just data existence check
  - Prevents data loss and duplicate processing
  - Maintains user selections across navigation
- **Race Condition Prevention**: Uses single initialization path with data existence check

#### Step 6: Add RPIs (`AddRPIsStep`)
- **Purpose**: Revenue Per Item column addition based on pack size relationships
- **Key Functions**: Pack size analysis, RPI preview, processing, enhanced file download
- **API Endpoints**: RPI analysis, preview, processing, file download
- **Data Flow**: Pack size analysis → RPI preview → Processing → Enhanced file
- **State Persistence**: RPI completion state is saved to localStorage for seamless workflow resumption
- **Comprehensive Cleanup**: Analysis deletion now properly cleans up localStorage RPI completion states
- **Visit Logic**: SIMPLIFIED - Only checks for existing RPI-enhanced files, no complex filename construction
- **Key Fixes Implemented**:
  - **Timing Issue Resolution**: Visit check only looks for existing files, doesn't construct future filenames
  - **State Persistence**: RPI completion data (columns added, success rate, etc.) saved to localStorage
  - **Simplified Flow**: No more premature file existence checks or confusing filename construction
  - **Proper State Restoration**: When returning to completed RPI step, shows final results without re-processing

#### Step 7: Data Summary (`DataSummaryStep`)
- **Purpose**: Comprehensive data overview with real-time filtering
- **Key Functions**: Data filtering, statistical analysis, data visualization
- **API Endpoints**: Filtered data retrieval, filter options
- **Data Flow**: Filter selection → Data filtering → Statistical analysis → Visualization

#### Step 8: Brand Selection (`BrandSelectionStep`)
- **Purpose**: Brand name input and validation
- **Key Functions**: Brand validation, context update, workflow continuation
- **Data Flow**: Brand input → Validation → Context update → Next step

#### Step 9: Filter Selection (`FilterSelectionStep`)
- **Purpose**: Interactive filter column selection for analysis customization
- **Key Functions**: Column selection, recommended filter highlighting, state management
- **Data Flow**: Column selection → Filter configuration → Context update

#### Step 10: Exploratory Data Analysis (`EDAStep`)
- **Purpose**: Comprehensive data exploration and statistical analysis
- **Key Functions**: Data distribution analysis, correlation matrix, data quality assessment
- **Data Flow**: Data loading → Statistical analysis → Visualization → Quality assessment

#### Step 11: Expected Signs (`ExpectedSignsStep`)
- **Purpose**: Variable relationship expectation setting for model building
- **Key Functions**: Sign specification, relationship direction, prior knowledge integration
- **Data Flow**: Variable loading → Sign selection → Relationship mapping → Model guidance

#### Step 12: Model Building (`ModelBuildingStep`)
- **Purpose**: Advanced model configuration and training interface
- **Key Functions**: Variable selection, model type configuration, training initiation
- **Data Flow**: Variable selection → Model configuration → Training → Results generation

#### Step 13: Model Results (`ModelResultsStep`)
- **Purpose**: Comprehensive model results display and interpretation
- **Key Functions**: Performance metrics, coefficient analysis, statistical significance, diagnostics
- **Data Flow**: Results loading → Metrics calculation → Significance analysis → Interpretation

#### Step 14: Optimizer (`OptimizerStep`)
- **Purpose**: Media budget optimization and scenario planning
- **Key Functions**: Scenario creation, budget optimization, ROI analysis, export capabilities
- **Data Flow**: Scenario setup → Optimization → Results analysis → Export

### 2.5 Non-MMM Analysis Workflow

The application also supports a comprehensive Non-MMM analysis workflow for custom statistical modeling and data insights:

#### Non-MMM Analysis Workflow
- **Purpose**: Non-MMM analysis follows the same brand setup flow as MMM analysis through DataScientistWizard
- **Brand Setup**: Handled in AnalysisTypeStep component within DataScientistWizard (same as MMM)
- **First Step**: Data Upload (NonMMMDataUploadStep) - auto-upload on file selection (like MMM)
- **API Endpoints**: Analysis CRUD operations via brandAnalysisService
- **Data Flow**: DataScientistWizard (brand input) → NonMMMWizard (data upload) → Analysis workflow

*Note: NonMMMAnalysisTypeStep component exists but is not used in the flow - brand setup is handled in DataScientistWizard*
- **Key Features**:
  - **Existing Analysis Display**: Shows existing non-MMM analyses in interactive cards with delete functionality
  - **Analysis Type Handling**: Properly converts between frontend 'non-mmm' and backend 'NON_MMM' formats
  - **Delete Capability**: Users can delete existing analyses with confirmation dialogs
  - **Resume Functionality**: Click on analysis cards to resume existing analyses
  - **State Persistence**: Maintains analysis state across sessions
- **Race Condition Prevention**: Uses centralized brandAnalysisService for all operations
- **Optimization**: Loads existing analyses on brand name change, updates local state for deletions

#### Non-MMM Analysis Steps
- **Data Upload**: File upload, sheet selection, brand management, state persistence integration
- **Target Variable Selection**: Interactive column selection for target variable with visual feedback
- **Expected Signs Configuration**: Variable relationship expectation setting (+ve, -ve, neutral)  
- **Data Summary**: Real-time statistical analysis from selected sheets, column type management, histogram visualization
- **Data Distribution**: Histogram generation for all variables with 4 charts per row layout
- **Chart Analysis**: Line charts with trendlines, scatter plots, variable relationship analysis
- **Model Building**: Model type selection (linear, log-linear, log-log, ridge, bayesian), variable selection via checkboxes, model training, and results display
- **Model Results**: Comprehensive model performance metrics, variable statistics, and model comparison

**Enhanced Features**:
- **Premium Design**: Sophisticated visual elements, enhanced animations, and premium styling
- **Better User Experience**: Improved navigation, progress tracking, and user engagement
- **Enhanced Visual Hierarchy**: Better typography, spacing, and visual organization
- **Sophisticated Animations**: Staggered animations, floating elements, and smooth transitions

#### Recent Non-MMM Implementation Updates (2025-01-31)
- **✅ Real Data Integration**: NonMMMDataSummaryStep now uses actual uploaded data from selected sheets instead of mock data
- **✅ State Persistence**: Sheet selections and file metadata are properly saved and restored using NonMMMStateService
- **✅ API Integration**: Complete integration with Python backend /api/nonmmm endpoints for data summary, histograms, and correlation matrices
- **✅ Column Type Management**: Real-time column type modification with backend synchronization
- **✅ Step State Management**: Proper state saving between Data Upload and Data Summary steps
- **✅ Target Variable Selection**: Added interactive target variable selection with state persistence and validation
- **✅ Complete Data Flow**: End-to-end data flow from sheet selection to analysis with proper state management
- **✅ Model Building Step**: Complete implementation of statistical modeling with model type selection, variable checkboxes, and real-time model training
- **✅ Backend Integration**: Python backend endpoints for model training, listing, and deletion with scikit-learn integration
- **✅ State Persistence**: Model configuration and results saved to state service for workflow continuity

#### Non-MMM Analysis Complete Implementation (2025-01-31)
- **✅ All 9 Steps Implemented**: Complete Non-MMM analysis workflow from data upload to model results
- **✅ Target Variable Selection Step**: Interactive column selection with visual feedback and state persistence
- **✅ Expected Signs Configuration Step**: Variable relationship expectation setting with toggle functionality
- **✅ Data Distribution Step**: Histogram generation for all variables with 4 charts per row layout and statistical insights
- **✅ Model Results Step**: Comprehensive model performance display with tabs for overview, model details, and variable analysis
- **✅ Enhanced Wizard Navigation**: Premium Non-MMM wizard with proper step routing, progress tracking, and navigation
- **✅ State Service Enhancement**: Added distribution state and model results persistence methods
- **✅ Complete Workflow**: Users can now complete entire Non-MMM analysis from start to finish with proper state management

### 3. Core Services

#### `BrandAnalysisService`
- **Purpose**: Comprehensive brand analysis management and state persistence
- **Key Functions**: Analysis CRUD operations, state management, progress tracking
- **API Endpoints**: Analysis management, state persistence, progress tracking
- **Data Flow**: Analysis lifecycle management → State persistence → Progress tracking

#### `MetadataService`
- **Purpose**: Advanced concatenation state persistence with validation and health monitoring
- **Key Functions**: State persistence, validation, health monitoring, state restoration
- **API Endpoints**: Metadata management, health checks, state validation
- **Data Flow**: State validation → Persistence → Health monitoring → Restoration

#### `WizardManager`
- **Purpose**: Intelligent wizard navigation and flow control
- **Key Functions**: Step validation, navigation logic, completion tracking, user-type handling
- **Data Flow**: Step validation → Navigation calculation → Completion tracking → State validation

#### `FileService`
- **Purpose**: File upload, processing, and data quality enhancement with type safety
- **Key Functions**: File upload, Excel processing, column modification, data quality filtering
- **Type Safety**: Uses `Record<string, unknown>` instead of `any` for dynamic API responses
- **API Endpoints**: File management, column modification, data quality enhancement
- **Data Flow**: File upload → Processing → Quality enhancement → Column modification
- **Error Handling**: Comprehensive error handling with fallback mechanisms and backend connectivity checks

#### `DataSummaryService`
- **Purpose**: Data summary operations and filtering
- **Key Functions**: Data filtering, statistics generation, filter options, error handling
- **API Endpoints**: Data filtering, summary statistics, column statistics
- **Data Flow**: Filter application → Data retrieval → Statistics generation → Error handling

### 4. State Management

#### `AnalysisContext`
- **Purpose**: Global state management for the entire analysis workflow
- **Key Features**:
  - Analysis data persistence
  - Step navigation management
  - User preferences and settings
  - Workflow state tracking
- **Data Flow**: State updates → Context propagation → Component re-rendering

### 5. Data Flow Architecture

#### Overall Workflow
1. **User Onboarding**: User type → Analysis type → Analysis mode
2. **Data Preparation**: File upload → Processing → Concatenation → RPIs
3. **Analysis Setup**: Data summary → Brand selection → Filter configuration
4. **Model Development**: EDA → Expected signs → Model building → Results
5. **Optimization**: Budget optimization → Scenario planning → Export

#### Non-MMM Analysis Workflow
1. **User Onboarding**: User type → Data Scientist → Non-MMM analysis type
2. **Brand Setup**: Brand name input → Existing analysis detection → Analysis creation/resumption
3. **Data Preparation**: File upload → Target variable selection → Expected signs configuration
4. **Data Analysis**: Data summary → Column type management → Distribution visualization
5. **Chart Analysis**: Variable relationship charts → Trendline analysis → Expected vs unexpected results
6. **Modeling**: Model selection → Variable selection → Model execution → Results analysis

#### Data Persistence Flow
1. **Local State**: Component-level state management
2. **Context State**: Global application state
3. **Backend Persistence**: Analysis metadata and state persistence
4. **File Storage**: Processed data and analysis results

#### API Communication Flow
1. **Frontend Request**: Service layer API calls
2. **Backend Processing**: Python FastAPI data processing
3. **Response Handling**: Data validation and error handling
4. **State Update**: Context and component state updates

### 6. Key Dependencies

#### Frontend Libraries
- **React 18**: Modern React with concurrent features
- **TypeScript**: Type-safe development
- **React Router**: Client-side routing
- **TanStack Query**: Server state management
- **Radix UI**: Accessible component primitives
- **Tailwind CSS**: Utility-first styling
- **Lucide React**: Icon library

#### Backend Integration
- **Python FastAPI**: Data processing and analysis backend
- **RESTful APIs**: Standardized API communication
- **File Processing**: Excel/CSV handling and manipulation
- **Data Analysis**: Statistical analysis and modeling

### 7. LoadingScreen Component

#### Epic Animated Loading Screen Implementation
**Purpose**: Sophisticated loading screen with animated Marico logo for premium user experience

**Features**:
- **Multi-layered Logo Animation**: Three rotating glow rings (outer, middle, inner) with different speeds and directions
- **Pulsing Effects**: Logo pulse animation with dynamic drop-shadow effects
- **Floating Background Elements**: Animated background circles with gradient effects
- **Loading Indicators**: Animated loading dots with staggered bounce effects
- **Smooth Transitions**: Three-phase animation (entering → active → exiting) with configurable duration
- **Responsive Design**: Adapts to all screen sizes with proper scaling
- **Logo Clarity Layer**: White background layer with subtle glow animation to ensure logo visibility

**Animation Sequence**:
1. **Growing Phase (1000ms)**: Logo scales up from 30% to 140% with organic blur and rotation effects, background glow rings appear
2. **Alive Phase (1000ms)**: Logo maintains 140% scale with breathing animations and dynamic color-shifting glow rings, all effects active
3. **Shrinking Phase (1000ms)**: Logo scales down from 140% to 10% with enhanced blur effects and gradual fade-out, glow rings disappear

**Technical Implementation**:
- React state management for animation phases
- Custom CSS animations with keyframes
- Configurable duration (default: 3000ms)
- Callback-based completion handling
- Z-index layering for proper display

**CSS Animations**:
- `spin-slow`: 8-second clockwise rotation for outer ring
- `spin-reverse`: 6-second counter-clockwise rotation for middle ring
- `logo-grow`: 1-second growth animation from 50% to 130% scale
- `logo-shrink`: 1-second shrinking animation from 130% to 20% scale
- `logo-spin-brake`: 2-second spinning animation with 5 full rotations and gradual braking
- `pulse-glow`: 3-second inner glow pulsing
- `white-glow`: 2.5-second subtle pulsing for white background layer
- `bounce`: 1.4-second staggered bounce for loading dots
- `float`: 6-second floating animation for background elements

**Integration**:
- Integrated into `App.tsx` with state management
- Displays before main application routing
- Seamless transition to main application
- No impact on application performance

### 8. Component Communication Patterns

#### Props and Callbacks
- **Parent-Child**: Direct prop passing for simple data flow
- **Event Callbacks**: Function props for user interactions
- **State Lifting**: Shared state in common parent components

#### Context Usage
- **Global State**: Analysis data, user preferences, workflow state
- **Shared Functions**: Navigation, state updates, API calls
- **Cross-Component Communication**: Step-to-step data passing

#### Service Integration
- **API Abstraction**: Service layer for backend communication
- **Error Handling**: Centralized error management and user feedback
- **Data Transformation**: Frontend data formatting and validation

### 8. Performance Considerations

#### State Optimization
- **Memoization**: React.memo and useMemo for expensive computations
- **State Splitting**: Granular state updates to minimize re-renders
- **Lazy Loading**: Component and data loading on demand

#### Data Management
- **Pagination**: Large dataset handling with pagination
- **Caching**: API response caching and state persistence
- **Debouncing**: User input optimization for search and filtering

### 9. Error Handling and User Experience

#### Global Error Boundary System
- **ErrorBoundary Component**: Catches React errors anywhere in the component tree
- **Retry Logic**: Maximum 2 retry attempts before redirecting to homepage
- **State Persistence**: Uses sessionStorage to track retry attempts across page refreshes
- **Automatic Recovery**: Redirects to homepage after failed retries with clean state reset
- **User-Friendly UI**: Shows retry and home options with clear error messages

#### Component-Level Error Management
- **API Errors**: Comprehensive error handling with user feedback
- **Validation Errors**: Form validation and user guidance
- **Fallback Data**: Graceful degradation when services are unavailable
- **useErrorHandler Hook**: Standardized error handling with retry logic and toast notifications

#### Error Flow
1. Error occurs → Error boundary catches it
2. First attempt → Show retry button, increment counter
3. Second attempt → Show retry button, increment counter  
4. Third attempt → Auto-redirect to homepage
5. Homepage loads → Reset error state, refresh once

#### User Feedback
- **Toast Notifications**: Success, error, and information messages
- **Loading States**: Progress indicators and skeleton screens
- **Progress Tracking**: Step completion and workflow progress
- **Development Testing**: ErrorTestComponent for testing error handling in development

### 10. Testing and Quality Assurance

#### Component Testing
- **Unit Tests**: Individual component functionality
- **Integration Tests**: Component interaction testing
- **User Experience Tests**: Workflow and navigation testing

#### Code Quality
- **TypeScript**: Compile-time error checking with strict type safety
- **Type Safety**: Uses `Record<string, unknown>` instead of `any` for dynamic API responses
- **ESLint**: Code style and best practices with TypeScript-specific rules
- **Prettier**: Code formatting consistency
- **Linter Compliance**: All services follow TypeScript best practices for type safety

## Conclusion

The BrandBloom Insights frontend is a sophisticated, well-architected React application that provides a comprehensive analytics workflow. The codebase follows modern React patterns, maintains clear separation of concerns, and provides excellent user experience through thoughtful design and robust error handling. The modular architecture makes it maintainable and extensible for future enhancements.

## Recent Fixes and Updates

### Folder Structure Optimization - Step Components Reorganization (2025-08-31)

#### Overview
Completed comprehensive reorganization of step components to improve logical grouping and maintainability by moving them from generic `components/steps/` to analysis-specific folders.

#### Changes Made:
1. **MMM Step Components**: Moved from `src/components/steps/mmm/` to `src/analysis/mmm/steps/`
2. **Non-MMM Step Components**: Moved from `src/components/steps/nonmmm/` to `src/analysis/nonmmm/steps/`
3. **Import Path Updates**: Updated all import statements throughout the codebase to reflect new locations
4. **Directory Cleanup**: Removed empty `src/components/steps/` directory structure

#### Benefits:
- **Better Organization**: Step components are now logically grouped under their respective analysis types
- **Cleaner Structure**: Eliminates the generic `components/steps/` folder in favor of analysis-specific organization
- **Easier Navigation**: Developers can find all MMM-related components in one place
- **Consistent Architecture**: Both MMM and Non-MMM follow the same organizational pattern

#### Updated Import Paths:
- MMM steps: `@/analysis/mmm/steps/`
- Non-MMM steps: `@/analysis/nonmmm/steps/`

#### Files Updated:
- All MMM page components (13 files)
- All Non-MMM page components (8 files)
- MMM wizard components (MMMWizard.tsx)
- Non-MMM wizard components (NonMMMWizard.tsx)
- Configuration files (stepConfig.ts)
- Service files with step component imports
- Documentation files

#### Testing:
- ✅ TypeScript compilation passes without errors
- ✅ All import paths correctly resolved
- ✅ No broken references or missing components
- ✅ Build process completes successfully

### Folder Structure Cleanup and Reorganization (2025-01-27)

#### Overview
Completed comprehensive cleanup and reorganization of the frontend folder structure to improve maintainability and follow best practices.

#### Changes Made:
1. **Component Reorganization**:
   - Moved MMM step components from `src/components/steps/mmm/` to `src/analysis/mmm/steps/`
   - Moved Non-MMM step components from `src/components/steps/nonmmm/` to `src/analysis/nonmmm/steps/`
   - Maintained proper separation between step components and page components

2. **Import Path Updates**:
   - Updated all import statements in page components to use new component paths
   - Updated DataScienceWizard.tsx to import from new step component locations
   - Updated NonMMMWizard.tsx to import from new step component locations
   - All import paths now correctly reference `@/analysis/mmm/steps/` and `@/analysis/nonmmm/steps/`

3. **Empty Directory Cleanup**:
   - Removed empty `src/analysis/mmm/components/` directory
   - Removed empty `src/analysis/nonmmm/components/` directory
   - Removed empty `src/services/nonmmm/` directory
   - Maintained directories with content (pages, types, services, wizard)

4. **Folder Structure Benefits**:
   - **Better Organization**: Step components are now logically grouped under `src/components/steps/`
   - **Clear Separation**: Analysis-specific logic (pages, types, services) remains in `src/analysis/`
   - **Improved Maintainability**: Easier to locate and manage step components
   - **Consistent Patterns**: Both MMM and Non-MMM analysis follow the same folder structure

#### Current Folder Structure:
```
src/
├── components/
│   ├── steps/
│   │   ├── mmm/        # MMM analysis step components
│   │   └── nonmmm/     # Non-MMM analysis step components
│   ├── ui/             # Reusable UI components
│   └── wizard/         # Wizard layout components
├── analysis/
│   ├── mmm/            # MMM analysis pages, types, services
│   └── nonmmm/         # Non-MMM analysis pages, types, services
└── services/            # Shared business logic services
```

#### Testing:
- ✅ TypeScript compilation passes without errors
- ✅ All import paths correctly resolved
- ✅ No broken references or missing components
- ✅ Folder structure follows React best practices

### Types Directory Creation and Import Path Resolution (2025-01-27)

#### Issue Identified:
The `NonMMMAnalysisTypeStep.tsx` component was experiencing import errors:
1. **Missing Service Import**: `Cannot find module '@/services/brandAnalysisService'`
2. **Missing Types Import**: `Cannot find module '@/types/analysis'`

#### Root Cause:
After the folder reorganization, the import paths were incorrect:
- `brandAnalysisService` was moved to `src/analysis/mmm/services/`
- `analysis.ts` types were in `src/analysis/mmm/types/`
- Many components throughout the application were importing from `@/types/analysis` which didn't exist

#### Solution Implemented:
1. **Service Import Fix**: Updated import path to `@/analysis/mmm/services/brandAnalysisService`
2. **Types Directory Creation**: Created `src/types/` directory for shared application types
3. **Types File Copy**: Copied `analysis.ts` to `src/types/` for application-wide access
4. **Import Path Standardization**: Updated component to use `@/types/analysis`

#### Benefits:
- **Centralized Types**: Shared types are now accessible from a single location
- **Import Consistency**: All components can use the same import path for analysis types
- **Better Organization**: Types are logically separated from analysis-specific components
- **Maintainability**: Easier to manage and update shared type definitions

#### Current Types Structure:
```
src/
├── types/
│   └── analysis.ts      # Shared analysis types used across application
└── analysis/
    ├── mmm/
    │   └── types/       # MMM-specific types (if any)
    └── nonmmm/
        └── types/       # Non-MMM-specific types
```

### RPI Step Flow Issues Resolution (2025-01-27)

#### Issues Fixed:
1. **Timing Issue**: FileService was checking for RPI-enhanced files before they were created, causing "file not found" errors
2. **Unnecessary Filename Construction**: Step 2 was constructing RPI-enhanced filenames instead of just checking for existing files
3. **Missing State Persistence**: RPI completion data wasn't being saved, causing users to lose progress when navigating away
4. **Complex Visit Logic**: Overly complicated visit detection that was causing confusion and errors

#### Root Causes:
1. **Premature File Checks**: The visit logic was checking for files before the RPI processing workflow was complete
2. **Filename Construction**: Step 2 was building future filenames instead of simply checking for existing completed files
3. **No State Persistence**: RPI completion results (columns added, success rate, etc.) weren't being saved anywhere
4. **Overcomplicated Logic**: Multiple file existence checks and complex filename matching logic

#### Solutions Implemented:
1. **Simplified Visit Logic**: 
   - **CRITICAL FIX**: Visit check now only looks for existing files with "with_rpis" in the name
   - No more filename construction or future file checking
   - Simple, reliable file existence detection
   - Eliminates timing issues and false "file not found" errors

2. **State Persistence**: 
   - **NEW**: RPI completion state is now saved to localStorage
   - Includes: columns added, rows processed, success rate, pack sizes, completion timestamp
   - Seamless workflow resumption without data loss
   - Proper state restoration when returning to completed RPI step

3. **Improved Flow Logic**:
   - **FIXED**: Step 2 now only checks if RPI is already complete
   - **FIXED**: No more premature file existence checks
   - **FIXED**: Clear separation between "checking completion" and "processing RPI"
   - **FIXED**: Proper state management for completed vs incomplete RPI steps

4. **Enhanced User Experience**:
   - **NEW**: When returning to completed RPI step, shows final results immediately
   - **NEW**: Completion timestamp and statistics are preserved
   - **NEW**: Download button remains available for completed RPI steps
   - **NEW**: No more confusing "file not found" messages

#### Code Changes:
- **AddRPIsStep.tsx**: 
  - Simplified visit logic to only check for existing RPI-enhanced files
  - Added RPICompletionState interface for state persistence
  - Implemented localStorage-based state saving
  - Enhanced complete tab to show saved completion data
  - Fixed timing issues and eliminated unnecessary filename construction
- **State Management**: Added comprehensive RPI completion state tracking
- **Visit Logic**: Streamlined to single, reliable file existence check

#### Benefits:
- **No More Timing Issues**: File existence checks only happen when files actually exist
- **Simplified Logic**: Single, clear visit detection without complex filename construction
- **State Persistence**: RPI completion data is preserved across navigation
- **Better UX**: Users see completion results immediately when returning to completed steps
- **Reliable Workflow**: No more false "file not found" errors or confusing messages
- **Seamless Navigation**: Users can navigate away and return without losing progress

#### Testing:
The fixes ensure that:
1. **First Visit**: Component properly detects new RPI analysis and starts workflow
2. **Processing**: RPI workflow completes normally and saves state
3. **Return Visit**: Component detects completed RPI and shows final results immediately
4. **State Persistence**: All completion data is preserved and restored correctly
5. **No False Errors**: No more "file not found" messages for files that don't exist yet
6. **Clean Flow**: Clear separation between completion checking and processing logic

### DataConcatenationStep Flow Issues Resolution
**Issue**: The DataConcatenationStep component was experiencing several flow problems:
1. **Premature filter loading**: Trying to load filters from backend even for new analyses where no filters were selected
2. **Wrong new vs existing analysis detection**: Flawed logic that prevented proper handling of new analyses
3. **Missing concatenation execution**: For new analyses, the component wasn't executing concatenation immediately when sheets were selected
4. **Component mounting confusion**: Overly complex mounting logic causing initialization issues
5. **Race conditions**: useEffect re-triggering during execution causing potential infinite loops
6. **Missing error handling**: No proper error handling for concatenation failures
7. **Duplicate execution prevention**: No guards against multiple simultaneous concatenation attempts
8. **State filename not captured**: Backend was returning state filename but frontend wasn't properly extracting it

**Root Cause**: 
1. **Filter loading logic**: The component was loading filters whenever `currentAnalysisId` existed, regardless of whether it was a new or existing analysis
2. **Analysis type detection**: Using `!analysisData?.isConcatenated` was insufficient - needed to check if `analysisData` exists at all
3. **Concatenation execution**: New analyses were waiting for user interaction instead of executing concatenation automatically when sheets were available
4. **Complex mounting**: Multiple useEffect hooks with complex dependencies were causing initialization timing issues
5. **Dependency array issues**: Including `analysisData` and `analysisData?.isConcatenated` in dependencies caused re-triggers during execution
6. **Missing state guards**: No protection against duplicate concatenation executions
7. **Incomplete error handling**: Errors during concatenation weren't properly caught and displayed to users
8. **State filename extraction**: Frontend wasn't properly extracting `stateFileName` and `stateFilePath` from backend response data structure

**Solution**: 
1. **Fixed filter loading**: Only load filters when `analysisData?.isConcatenated` is true AND filters were previously set (`analysisData?.selectedFilters && analysisData.selectedFilters.length > 0`)
2. **Improved analysis detection**: Changed logic to `!analysisData || !analysisData.isConcatenated` for proper new analysis detection
3. **Auto-execute concatenation**: For new analyses, automatically execute concatenation when sheets are selected instead of waiting
4. **Simplified initialization**: Streamlined the initialization logic to be more predictable
5. **Prevented race conditions**: Simplified dependency array to only include stable values (`hasMounted`, `currentAnalysisId`, `selectedBrand`)
6. **Added state guards**: Implemented `isConcatenationInProgress` state to prevent duplicate executions
7. **Comprehensive error handling**: Added try-catch blocks with proper error messages and state reset
8. **Cleanup effects**: Added cleanup effects to reset state when component unmounts or analysis changes
9. **Fixed state filename extraction**: Properly extract `stateFileName` and `stateFilePath` from `result.data` structure and store in analysis data

**Files Modified**:
- `src/components/steps/DataConcatenationStep.tsx` - Fixed filter loading, analysis detection, concatenation execution logic, race conditions, error handling, and state management
- `src/services/metadataService.ts` - Fixed state filename extraction from backend response
- `Backend/python/app/models/data_models.py` - Added stateFileName and stateFilePath fields to StateResponse model
- `Backend/python/app/routes/metadata_routes.py` - Updated route to properly extract and return state filename fields

**Impact**: 
- **New analyses**: Now automatically execute concatenation when sheets are selected, providing immediate feedback
- **Existing analyses**: Properly restore state without unnecessary filter loading
- **Cleaner flow**: No more premature backend calls or confusing initialization messages
- **Better UX**: Users see immediate progress instead of waiting for manual interaction
- **Race condition prevention**: No more infinite loops or duplicate executions
- **Robust error handling**: Proper error messages and recovery mechanisms
- **State consistency**: Clean state management with proper cleanup
- **State filename persistence**: State filename is now properly captured and stored for seamless workflow resumption

### Duplicate Flow Issue Resolution
**Issue**: The frontend was experiencing duplicate initialization flows where both new analysis creation and analysis overwriting were calling the same `initializeNewAnalysis()` method, causing confusion and potential race conditions. Additionally, duplicate console.log statements were making it appear as if there were multiple calls when there was actually just one call with multiple log statements.

**Root Cause**: 
1. `handleMMMWithBrand()` was calling `initializationService.initializeNewAnalysis()` for new analyses
2. `handleOverwriteAnalysis()` was also calling `initializationService.initializeNewAnalysis()` for overwriting existing analyses
3. Both flows were going through the same path, making it unclear whether it was a new analysis or an overwrite operation
4. **Duplicate logging**: Both `initializationService` and `brandAnalysisService` were logging the same messages, creating the appearance of duplicate calls

**Solution**: 
1. **Enhanced `initializeNewAnalysis()` method**: Added `forceOverwrite` parameter support to handle both new and overwrite cases
2. **New `overwriteExistingAnalysis()` method**: Created a dedicated method that internally calls `initializeNewAnalysis(forceOverwrite: true)` for clarity
3. **Updated `handleOverwriteAnalysis()`**: Now calls the dedicated overwrite method instead of the generic initialization method
4. **Improved flow separation**: Clear distinction between new analysis, overwrite analysis, and resume analysis workflows
5. **Eliminated duplicate logging**: Removed duplicate console.log statements from `initializationService` to prevent confusion about duplicate calls

**Files Modified**:
- `src/services/initializationService.ts` - Added forceOverwrite support, new overwrite method, and removed duplicate logging
- `src/components/steps/AnalysisTypeStep.tsx` - Updated to use dedicated overwrite method
- `FRONTEND_CODEBASE_DOCUMENTATION.mdc` - Updated documentation to reflect new architecture

**Impact**: This ensures a single, clear flow for each type of analysis operation:
- **New Analysis**: `initializeNewAnalysis()` → Brand check → Analysis creation
- **Overwrite Analysis**: `overwriteExistingAnalysis()` → Force overwrite → Analysis recreation  
- **Resume Analysis**: `resumeExistingAnalysis()` → Load existing → State restoration
- **Cleaner Logs**: No more duplicate log messages that could confuse debugging

### Metadata Service Filename Issue Resolution
**Issue**: The metadata service was logging "filename not returned" instead of the actual filename from the backend response.

**Root Cause**: The backend response structure was not being properly logged for debugging, making it difficult to identify why the filename wasn't being returned.

**Solution**: Added comprehensive response structure debugging in `metadataService.ts` to log the complete backend response, including `stateFileName` and `stateFilePath` fields. This will help identify any mismatches between frontend expectations and backend response structure.

**Files Modified**:
- `src/services/metadataService.ts` - Added response structure debugging

### Sheet Name Standardization
**Issue**: The frontend and backend were using inconsistent sheet names. The frontend used "Concatenated_Data" while the user specified it should be "Concatenated_Data_Enhanced".

**Root Cause**: Hardcoded sheet names were scattered across multiple services and components, leading to inconsistencies between frontend and backend.

**Solution**: Updated all sheet name references from "Concatenated_Data" to "Concatenated_Data_Enhanced" across the entire codebase to ensure consistency.

**Files Modified**:
- `src/services/rpiAdditionService.ts` - Updated default sheet names in all RPI methods
- `../backend/python/app/services/excel_service.py` - Updated Excel writer sheet name
- `../backend/python/app/models/data_models.py` - Updated default sheet name in data models
- `../backend/python/app/services/rpi_addition_service.py` - Updated default sheet name
- `../backend/python/app/routes/rpi_addition_routes.py` - Updated form defaults and documentation
- `../backend/python/app/services/rpi_addition/rpi_addition_service.py` - Updated default sheet name
- `../backend/python/app/services/rpi_addition/excel_file_handler.py` - Updated fallback sheet name options

**Impact**: This ensures that all services (frontend and backend) use the same sheet name "Concatenated_Data_Enhanced" for concatenated data, preventing sheet name mismatches and improving data consistency across the application.

### 11. Wizard Flow Architecture Fix (2025-01-27)

#### Issues Fixed:
1. **User Being Pushed Back to Step 1**: After selecting Data Scientist → MMM → entering brand name, users were being pushed back to step 1 instead of continuing the workflow
2. **Fragmented Wizard Architecture**: Each wizard was independent and started from step 1, causing users to lose progress when navigating between wizards
3. **Missing Step Completion Tracking**: No system to track which steps had been completed, making it impossible to resume from where users left off
4. **Poor User Experience**: Users had to re-select options they had already chosen, creating confusion and frustration

#### Root Causes:
1. **Separate Wizard Components**: InitialWizard, DataScientistWizard, and MMMWizard were completely separate components
2. **State Reset on Navigation**: When navigating between wizards, the AnalysisContext state was being reset
3. **No Progress Persistence**: No mechanism to remember completed steps across wizard transitions
4. **Complex Routing Logic**: Multiple navigation jumps between different wizard components

#### Solutions Implemented:

##### 1. **Unified Wizard Flow**
- **DataScientistWizard**: Now handles both analysis type selection AND analysis mode selection
- **Step Continuity**: Users stay within the same wizard for steps 1-3 instead of jumping between components
- **Progressive Disclosure**: Only navigate to MMMWizard after completing all setup steps

##### 2. **Step Completion Tracking System**
- **New Context Functions**: Added `markStepCompleted()`, `isStepCompleted()`, `getCompletedSteps()`, `resetStepCompletion()`
- **Progress Persistence**: System now tracks which steps have been completed
- **Resume Functionality**: Users can resume from where they left off instead of starting over

##### 3. **Smart Step Resumption**
- **Automatic Detection**: MMMWizard automatically detects completed steps and starts from the appropriate step
- **Resume Button**: Shows resume option when users return to step 1 with completed progress
- **Progress Display**: Shows completed steps and allows users to choose between resuming or starting over

##### 4. **Improved User Experience**
- **No More Step 1 Returns**: Users are no longer pushed back to step 1 after completing setup
- **Seamless Flow**: Smooth progression from user type → analysis type → analysis mode → data upload
- **Clear Progress Indication**: Users can see exactly where they are in the workflow

#### Code Changes Made:

##### **DataScientistWizard.tsx**
- Added AnalysisModeStep integration for MMM workflow continuation
- Implemented step completion tracking with `markStepCompleted()`
- Added local step management (currentStep state)
- Enhanced navigation logic to continue MMM workflow within the same wizard

##### **MMMWizard.tsx**
- Added resume functionality with progress display
- Implemented smart step detection based on completed steps
- Added resume button for users with existing progress
- Enhanced step component rendering with progress awareness

##### **AnalysisContext.tsx**
- Added `completedSteps` array to AppState interface
- Implemented step completion actions and reducer logic
- Added context functions for step completion management
- Enhanced state persistence across wizard transitions

##### **appConstants.ts**
- Fixed step configuration mismatch (was 13 steps, now properly 14 steps)
- Added missing "Add RPIs" step to STEP_NAMES and STEP_TITLES
- Updated TOTAL_STEPS to 14 to match actual workflow

#### New User Flow:

1. **InitialWizard** (`/`) → User selects "Data Scientist"
2. **DataScientistWizard** (`/data-scientist`) → Step 1: Analysis Type Selection
3. **DataScientistWizard** (`/data-scientist`) → Step 2: Analysis Mode Selection (for MMM)
4. **MMMWizard** (`/mmm`) → Step 4: Data Upload (automatically starts from correct step)

#### Benefits:

- **No More Step 1 Returns**: Users maintain their progress through the workflow
- **Seamless Experience**: Smooth transition between setup and execution phases
- **Progress Persistence**: Users can resume from where they left off
- **Better UX**: Clear indication of progress and completion status
- **Maintainable Code**: Unified wizard flow instead of fragmented components

#### Testing Status:
- ✅ **Step Continuity**: Users no longer return to step 1 after completing setup
- ✅ **Progress Tracking**: Step completion is properly tracked and persisted
- ✅ **Resume Functionality**: Users can resume from completed steps
- ✅ **Navigation Flow**: Smooth progression through the wizard without jumps
- ✅ **State Persistence**: AnalysisContext maintains state across wizard transitions

#### Key Lessons Learned:
1. **Wizard Architecture**: Single, unified wizard flows are better than multiple separate wizards
2. **State Management**: Step completion tracking is essential for good user experience
3. **Progress Persistence**: Users should never lose progress when navigating between components
4. **User Flow Design**: Minimize navigation jumps and maintain context continuity
5. **Resume Functionality**: Always provide users with the option to resume from where they left off

#### Future Enhancements:
1. **Enhanced Progress Tracking**: Add more granular step completion criteria
2. **Workflow Customization**: Allow users to skip certain steps based on their needs
3. **Progress Visualization**: Add progress bars and step completion indicators
4. **Auto-save**: Automatically save progress as users complete steps
5. **Session Recovery**: Recover progress if users accidentally close the browser

### 12. Route Guard Implementation & Premature Mounting Fix (2025-01-27)

#### Issues Fixed:
1. **Premature MMMWizard Mounting**: MMMWizard was mounting immediately when users hadn't made any selections
2. **Incorrect Wizard Flow**: Users could access specialized wizards without completing the proper user flow
3. **Architectural Confusion**: The routing logic was allowing direct access to MMMWizard and NonMMMWizard
4. **Console Warnings**: MMMWizard was logging warnings about conditions not being met for auto-advancement
5. **Unnecessary Analysis Mode Step**: An extra "Analysis Mode" step was added that was never supposed to exist

#### Root Causes:
1. **Missing Route Protection**: No validation that users had completed the proper flow before accessing specialized wizards
2. **Direct Route Access**: Users could navigate directly to `/mmm/*` routes without going through user type and analysis type selection
3. **Wizard Responsibility Overlap**: MMMWizard was trying to handle steps 1-3 which should be handled by other wizards
4. **No Access Control**: Specialized wizards had no way to validate user flow completion
5. **Extra Step Added**: The "Analysis Mode" step was mistakenly introduced when it wasn't part of the original design

#### Solutions Implemented:

##### 1. **Route Guard System**
- **RouteGuard Component**: Generic route protection component that validates user flow completion
- **MMMRouteGuard**: Specific guard for MMM analysis routes requiring data-scientist + mmm
- **NonMMMRouteGuard**: Specific guard for Non-MMM analysis routes requiring data-scientist + non-mmm
- **Access Validation**: Prevents access to protected routes unless proper conditions are met

##### 2. **Proper Wizard Separation (RESTORED)**
- **InitialWizard** (`/`) → Only handles user type selection (Brand Leader vs Data Scientist)
- **DataScientistWizard** (`/data-scientist`) → Only handles analysis type selection (MMM vs Non-MMM)
- **MMMWizard** (`/mmm/*`) → Handles MMM workflow (steps 1-11: Data Upload through Optimizer)
- **NonMMMWizard** (`/nonmmm/*`) → Handles Non-MMM specific workflow

##### 3. **Route Protection Implementation**
- **App.tsx**: Wraps MMMWizard and NonMMMWizard with their respective route guards
- **Access Control**: Routes are protected at the React Router level
- **Automatic Redirects**: Users are redirected to appropriate starting points if flow is incomplete
- **Loading States**: Shows loading indicators while validating access

##### 4. **Cleaner MMMWizard Architecture (RESTORED)**
- **Removed Premature Logic**: Eliminated useEffect hooks that were causing premature mounting
- **Step Range**: MMMWizard now handles steps 1-11 (Data Upload through Optimizer)
- **No User Selection**: MMMWizard no longer handles user type or analysis type selection
- **Focused Responsibility**: Each wizard now has a single, clear responsibility
- **Removed Analysis Mode**: The unnecessary "Analysis Mode" step has been completely removed

#### Code Changes Made:

##### **RouteGuard.tsx (NEW)**
- Generic route protection component with validation logic
- Specific guards for MMM and Non-MMM analysis routes
- Automatic redirects for incomplete user flows
- Loading states during access validation

##### **App.tsx**
- Added route guard imports
- Wrapped MMMWizard and NonMMMWizard with their respective guards
- Updated documentation to reflect new routing architecture

##### **MMMWizard.tsx**
- Removed premature mounting logic and useEffect hooks
- Eliminated user type and analysis type selection handling
- Updated step range to handle steps 1-11 (Data Upload through Optimizer)
- Added proper step validation and redirection logic

##### **DataScientistWizard.tsx**
- Removed the unnecessary "Analysis Mode" step
- Restored original flow: Analysis Type selection → Direct to MMMWizard
- Simplified to single step wizard (Analysis Type selection only)

#### New Protected Routing Architecture (RESTORED):

```
/ (InitialWizard) → User Type Selection
├── /brand-leader (BrandLeaderWizard) → Brand Leader workflow
└── /data-scientist (DataScientistWizard) → Analysis Type Selection (includes brand setup)
    ├── /mmm/* (MMMRouteGuard + MMMWizard) → MMM workflow (steps 1-11)
    └── /nonmmm (NonMMMRouteGuard + NonMMMWizard) → Non-MMM workflow (starts at data upload)
```

#### Route Guard Validation Rules:

##### **MMMRouteGuard**
- **Required**: `userType === 'data-scientist'`
- **Required**: `analysisType === 'mmm'`
- **Redirect**: `/data-scientist` if conditions not met

##### **NonMMMRouteGuard**
- **Required**: `userType === 'data-scientist'`
- **Required**: `analysisType === 'non-mmm'`
- **Redirect**: `/data-scientist` if conditions not met

#### Benefits:

- **No More Premature Mounting**: Specialized wizards only mount after proper user flow completion
- **Proper Access Control**: Users cannot access advanced features without completing setup
- **Cleaner Architecture**: Each wizard has a single, focused responsibility
- **Better User Experience**: Clear progression through the workflow without confusion
- **Security**: Prevents unauthorized access to specialized analysis tools
- **Maintainability**: Clear separation of concerns between different wizard components
- **Original Flow Restored**: MMM analysis now follows the intended 2-step setup flow

#### Testing Status:
- ✅ **Route Protection**: Specialized wizards are properly protected
- ✅ **Access Validation**: Users cannot access protected routes without proper flow completion
- ✅ **Automatic Redirects**: Users are redirected to appropriate starting points
- ✅ **No Premature Mounting**: MMMWizard only mounts after proper user selections
- ✅ **Clean Console**: No more warnings about conditions not being met
- ✅ **Proper Flow**: Users must complete setup before accessing specialized features
- ✅ **Analysis Mode Removed**: The unnecessary step has been completely eliminated
- ✅ **Original Flow Restored**: MMM analysis follows the intended 2-step setup

#### Key Lessons Learned:
1. **Route Protection**: Always protect specialized routes with proper validation
2. **Wizard Separation**: Each wizard should have a single, clear responsibility
3. **Access Control**: Validate user flow completion before allowing access to advanced features
4. **Architecture Design**: Prevent premature mounting by implementing proper route guards
5. **User Experience**: Ensure users follow the intended workflow progression
6. **Don't Add Unnecessary Steps**: Stick to the original design unless there's a clear need for additional steps

#### Future Enhancements:
1. **Enhanced Route Guards**: Add more sophisticated validation logic
2. **Permission System**: Implement role-based access control for different user types
3. **Session Validation**: Add session timeout and validation
4. **Audit Logging**: Track route access attempts and user flow progression
5. **Custom Error Pages**: Provide better error messages for unauthorized access attempts
6. **Analysis Cleanup**: Implement proper analysis deletion through API endpoints instead of manual folder deletion

### 13. Duplicate Function Identifier Fix (2025-01-27)

#### Issue Identified:
The frontend was experiencing a critical startup error:
```
Uncaught SyntaxError: Identifier 'cleanupAllAnalyses' has already been declared (at analysisCleanup.ts?t=1756496691502:88:12)
```

#### Root Cause:
The `src/utils/analysisCleanup.ts` file contained two functions with the same name:
1. **Line 88**: `export async function cleanupAllAnalyses(brandName: string): Promise<boolean>` - takes a brand name parameter
2. **Line 118**: `export async function cleanupAllAnalyses(): Promise<boolean>` - takes no parameters

This caused a JavaScript syntax error because you cannot declare the same identifier twice in the same scope.

#### Solution Implemented:
1. **Function Renaming**: Renamed the second function from `cleanupAllAnalyses()` to `cleanupAllSystemAnalyses()` to be more descriptive
2. **Import Updates**: Updated `src/utils/devConsole.ts` to import the renamed function
3. **Documentation Updates**: Updated function documentation to clarify the difference between:
   - `cleanupAllAnalyses(brandName)`: Deletes all analyses for a specific brand
   - `cleanupAllSystemAnalyses()`: Deletes all analyses in the entire system

#### Code Changes Made:
- **analysisCleanup.ts**: 
  - Renamed `cleanupAllAnalyses()` → `cleanupAllSystemAnalyses()`
  - Updated function documentation to reflect new naming
- **devConsole.ts**: 
  - Updated import statement to use new function name
  - Updated `cleanupAll()` console function to use `cleanupAllSystemAnalyses`
  - Enhanced documentation to clarify what `cleanupAll()` does

#### Benefits:
- **No More Startup Errors**: Frontend now starts successfully without syntax errors
- **Clear Function Naming**: Function names now clearly indicate their purpose
- **Better Code Organization**: No more duplicate identifier conflicts
- **Improved Maintainability**: Clear distinction between brand-specific and system-wide cleanup
- **Development Console**: `cleanupAll()` function now properly cleans up entire system

#### Testing Status:
- ✅ **Build Success**: `npm run build` completes without errors
- ✅ **Development Server**: `npm run dev` starts successfully on port 8081
- ✅ **No Syntax Errors**: All duplicate identifier issues resolved
- ✅ **Function Clarity**: Clear distinction between cleanup functions
- ✅ **Import Resolution**: All imports properly resolved

#### Key Lessons Learned:
1. **Function Naming**: Always use unique, descriptive names for exported functions
2. **Code Review**: Check for duplicate identifiers during code review
3. **Testing**: Always test both build and development server after making changes
4. **Documentation**: Keep function documentation synchronized with actual function names
5. **Import Management**: Update all import statements when renaming functions

#### Function Reference:
- **`cleanupAnalysis(analysisId)`**: Delete specific analysis by ID
- **`cleanupAllAnalyses(brandName)`**: Delete all analyses for a specific brand
- **`cleanupAllSystemAnalyses()`**: Delete all analyses in the entire system
- **`cleanupXMenAnalysis()`**: Development utility for X-Men brand cleanup
- **`cleanupMBLAnalysis()`**: Development utility for MBL brand cleanup
- **`cleanup210825Analysis()`**: Development utility for 210825 brand cleanup

### Critical Issues Resolution (2025-01-27)

#### Overview
Resolved several critical issues that were causing console pollution, routing errors, and user experience problems in the BrandBloom Insights application.

#### Issues Fixed:

##### 1. **Hardcoded Brand References Issue**
- **Problem**: Console logs showing hardcoded "cmen" and "mbl" references on app startup
- **Root Cause**: Development cleanup functions in `devConsole.ts` and `analysisCleanup.ts` had hardcoded brand names
- **Solution**: 
  - Removed hardcoded brand-specific cleanup functions (`cleanupXMenAnalysis`, `cleanupMBLAnalysis`, `cleanup210825Analysis`)
  - Created generic `cleanupBrandAnalyses(brandName)` function for any brand
  - Updated `devConsole.ts` to use generic function: `cleanupBrand('X-Men')` instead of `cleanupXMen()`
- **Benefits**: No more console pollution with hardcoded brand references, cleaner development utilities

##### 2. **Export Resolution Logs Issue**
- **Problem**: Console logs showing "export resolution" messages on every app startup
- **Root Cause**: Services index file had debug logging that ran on every import
- **Solution**: Removed all debug logging from `src/analysis/mmm/services/index.ts`
- **Benefits**: Clean console on app startup, no unnecessary logging pollution

##### 3. **Expected Signs Logs Issue**
- **Problem**: Console logs about "expected signs" when user hasn't done anything
- **Root Cause**: Services were being imported and initialized on app startup with debug logging
- **Solution**: Removed startup logging from services index file
- **Benefits**: No more confusing logs about features user hasn't accessed yet

##### 4. **MMM Analysis Deletion Issue**
- **Problem**: Delete button not fully deleting MMM analysis, analysis reappearing after deletion
- **Root Cause**: Analysis metadata persisted in backend even after folder deletion
- **Solution**: 
  - Enhanced cleanup functions to use proper API endpoints instead of manual folder deletion
  - Implemented comprehensive cleanup through `brandAnalysisService.deleteAnalysis()`
  - Added proper error handling and success tracking
- **Benefits**: Proper analysis cleanup, no more reappearing analyses, consistent state management

##### 5. **404 Route Error Issue**
- **Problem**: 404 error for `/step/5/data-concatenation` route when trying to concatenate data
- **Root Cause**: Route structure mismatch between old step-based routing (`/step/5/data-concatenation`) and new wizard routing (`/mmm/step/2`)
- **Solution**: 
  - Updated all navigation calls in step components to use new wizard routing
  - Fixed `AnalysisTypeStep.tsx` to navigate to `/mmm/step/2` instead of `/step/5/data-concatenation`
  - Fixed `DataUploadStep.tsx` to navigate to `/mmm/step/2` instead of old routes
  - Fixed `ExistingAnalysisSelection.tsx` to use new routing structure
- **Benefits**: Proper navigation flow, no more 404 errors, consistent routing architecture

##### 6. **Step Configuration Mismatch**
- **Problem**: MMMWizard showed 11 steps but constants defined 14 steps, causing confusion
- **Root Cause**: Inconsistent step counting between different components and constants
- **Solution**: 
  - Standardized step configuration to 13 steps (removed unnecessary "Analysis Mode" step)
  - Updated `appConstants.ts` to have consistent `STEP_NAMES` and `STEP_TITLES`
  - Fixed `TOTAL_STEPS` from 14 to 13
  - Updated `MMMWizard.tsx` to handle 13 steps properly
- **Benefits**: Consistent step configuration, no more step count confusion, proper workflow progression

#### Files Modified:
- **`src/utils/analysisCleanup.ts`**: Removed hardcoded brand functions, added generic cleanup
- **`src/utils/devConsole.ts`**: Updated to use generic cleanup function
- **`src/analysis/mmm/services/index.ts`**: Removed debug logging
- **`src/constants/appConstants.ts`**: Fixed step configuration and counts
- **`src/analysis/mmm/wizard/MMMWizard.tsx`**: Updated to handle 13 steps and fixed analysis state persistence
- **`src/analysis/mmm/steps/AnalysisTypeStep.tsx`**: Fixed navigation routes
- **`src/analysis/mmm/steps/DataUploadStep.tsx`**: Fixed navigation to use `nextStep()` from context instead of hardcoded routes
- **`src/analysis/mmm/steps/ExistingAnalysisSelection.tsx`**: Fixed navigation routes
- **`src/analysis/nonmmm/wizard/NonMMMWizard.tsx`**: Fixed navigation routes

#### Testing Status:
- ✅ **No More Hardcoded References**: Console is clean of hardcoded brand names
- ✅ **No More Export Resolution Logs**: Services index no longer pollutes console on startup
- ✅ **No More Expected Signs Logs**: No confusing logs about unused features
- ✅ **Proper Analysis Deletion**: Delete button now properly removes analyses
- ✅ **No More 404 Errors**: All navigation uses correct wizard routing
- ✅ **Consistent Step Configuration**: All components show same step count and names
- ✅ **Complete Fresh Start**: "Start Fresh Analysis" now properly deletes backend state and provides true clean slate
- ✅ **Manual Cleanup Options**: Added debugging tools for persistent state issues

#### Key Lessons Learned:
1. **Development Utilities**: Keep development functions generic, avoid hardcoded values
2. **Console Logging**: Remove or conditionally show debug logging to prevent pollution
3. **Routing Architecture**: Ensure all components use consistent routing patterns
4. **Step Configuration**: Maintain single source of truth for step definitions
5. **Cleanup Functions**: Use proper API endpoints instead of manual file operations
6. **Navigation Consistency**: Update all navigation calls when changing routing architecture
7. **State Persistence**: Ensure both frontend and backend state are properly managed and cleaned up

#### Future Prevention:
1. **Code Review**: Check for hardcoded values during code reviews
2. **Logging Standards**: Establish guidelines for when and how to use console logging
3. **Routing Validation**: Validate routing consistency across components
4. **Configuration Management**: Centralize step and configuration management
5. **Testing**: Add automated tests for navigation and routing functionality
6. **State Management**: Implement comprehensive state cleanup that covers both frontend and backend

### 14. MMMWizard Step Completion Detection Fix (2025-01-27)

#### Issues Fixed:
1. **Incorrect Step Completion Detection**: The system was incorrectly detecting steps 3, 4, and 6 as completed for new analyses when the user was just starting
2. **Complex Cleanup Code**: The MMMWizard contained overly complex cleanup logic that was causing confusion and potential errors
3. **State vs Progress Confusion**: The system was checking for data existence in state rather than actual user progress through steps

#### Root Causes:
1. **Step Completion Logic**: The `getCompletedSteps()` function was marking steps as completed based on data existence rather than actual user progress
2. **New vs Existing Analysis Confusion**: The logic didn't distinguish between new analyses (where data might be initialized but not completed) and existing analyses (where steps were actually completed)
3. **Overcomplicated Cleanup**: Complex cleanup operations with multiple fallback mechanisms were making the code hard to maintain

#### Solutions Implemented:

##### 1. **Fixed Step Completion Detection**
- **New Analysis Protection**: Steps 3+ are now only marked as completed if `state.currentAnalysisId` exists (indicating an existing analysis)
- **Conservative Logic**: The system now only marks steps as completed when there's clear evidence the user has actually progressed through them
- **State vs Progress Separation**: Clear distinction between having data in state vs. actually completing workflow steps

##### 2. **Simplified Cleanup Operations**
- **Removed Complex Cleanup**: Eliminated all complex cleanup logic including backend deletion, browser storage clearing, and page reloads
- **Simple Reset**: "Start Fresh Analysis" now simply calls `resetAnalysis()` and `goToStep(1)`
- **No More Reloads**: Eliminated forced page refreshes that were causing user experience issues

##### 3. **Cleaner Step Logic**
- **Step 1-2**: User Type and Analysis Type (handled by other wizards)
- **Step 3+**: Only marked as completed for existing analyses with `currentAnalysisId`
- **No False Positives**: New analyses will show 0-2 completed steps instead of 5-6

#### Code Changes Made:

##### **MMMWizard.tsx**
- **Fixed `getCompletedSteps()`**: Added `state.currentAnalysisId` check for all steps 3+
- **Simplified "Start Fresh Analysis"**: Removed complex cleanup, now just resets state
- **Removed Cleanup Imports**: Eliminated unused `initializationService` import
- **Cleaner Logic**: Each step completion check now requires both data existence AND analysis ID

#### Benefits:
- **No More False Step Detection**: New analyses correctly show 0-2 completed steps
- **Simpler Code**: Removed complex cleanup logic that was causing confusion
- **Better User Experience**: Users see accurate progress indication
- **Cleaner State Management**: Clear separation between new and existing analyses
- **Maintainable Code**: Simpler logic that's easier to debug and maintain

#### Testing Status:
- ✅ **Step Detection Fixed**: New analyses no longer show incorrect completed steps
- ✅ **Cleanup Simplified**: "Start Fresh Analysis" works without complex operations
- ✅ **No More False Positives**: Steps 3+ only marked as completed for existing analyses
- ✅ **Clean Console**: No more confusing step completion messages for new users
- ✅ **Proper Flow**: Users can now progress through the workflow without confusion

#### Key Lessons Learned:
1. **Step Completion Logic**: Always distinguish between data existence and actual step completion
2. **New vs Existing Analysis**: Use `currentAnalysisId` to determine analysis state
3. **Conservative Detection**: Only mark steps as completed when there's clear evidence
4. **Simple Cleanup**: Complex cleanup operations often cause more problems than they solve
5. **State vs Progress**: Don't confuse having data in state with completing workflow steps

#### Future Enhancements:
1. **Step Validation**: Add more granular step completion criteria
2. **Progress Tracking**: Implement proper step-by-step progress tracking
3. **User Feedback**: Add clear indicators for what constitutes step completion
4. **State Persistence**: Improve state management for better workflow resumption
5. **Error Handling**: Add better error handling for step completion detection

### 15. ESLint React Hooks Exhaustive Dependencies Fix (2025-01-27)

#### Issue Fixed:
The MMMWizard component had an ESLint warning about missing dependencies in the useEffect hook:
```
React Hook useEffect has missing dependencies: 'state.analysisType', 'state.currentStep', and 'state.userType'. 
Either include them or remove the dependency array.
```

#### Root Cause:
The useEffect hook was using state values (`state.userType`, `state.analysisType`, `state.currentStep`) inside the effect but had an empty dependency array `[]`. This violates the React hooks exhaustive-deps rule and can lead to stale closures.

#### Solution Implemented:
1. **Added useRef for Mount Tracking**: Used `useRef(false)` to track if the component has already mounted
2. **Fixed Dependency Array**: Added all used state values to the dependency array: `[state.userType, state.analysisType, state.currentStep]`
3. **Conditional Logging**: The logging now only happens once when the component first mounts, preventing duplicate logs

#### Code Changes Made:
- **MMMWizard.tsx**: 
  - Added `useRef` import
  - Added `hasMounted` ref to track mount state
  - Fixed useEffect dependency array to include all used state values
  - Added conditional logic to prevent duplicate logging

#### Benefits:
- **ESLint Compliance**: No more warnings about missing dependencies
- **Proper React Patterns**: Follows React hooks best practices
- **No Stale Closures**: State values are always current when accessed
- **Single Logging**: Prevents duplicate mount logs
- **Better Code Quality**: Maintains proper dependency tracking

#### Testing Status:
- ✅ **ESLint Compliance**: No more exhaustive-deps warnings
- ✅ **Proper Dependencies**: All state values are properly tracked
- ✅ **Single Mount Log**: Component only logs once when mounting
- ✅ **No Breaking Changes**: Functionality remains exactly the same

### 16. Welcome Back Message False Positive Fix (2025-01-27)

#### Issue Fixed:
The MMMWizard was incorrectly showing "Welcome Back to MMM Analysis!" message for brand new analyses, even when no prior analysis existed. This was confusing users who were starting their first analysis.

#### Root Cause:
The `getCompletedSteps()` function was incorrectly treating user type selection (`userType: "data-scientist"`) and analysis type selection (`analysisType: "mmm"`) as "completed workflow steps" when they are actually just setup prerequisites, not part of the actual analysis workflow.

**Problem Flow:**
1. User selects "Data Scientist" → `userType` set in context
2. User selects "MMM" → `analysisType` set in context  
3. `getCompletedSteps()` sees these values and marks steps 1-2 as "completed"
4. System shows "Welcome Back" message with "You have completed 2 steps"
5. User sees confusing message when they haven't actually done any analysis work

#### Solution Implemented:
**Critical Logic Change**: Only show "Welcome Back" for existing analyses with a valid `currentAnalysisId`. For new analyses, user type and analysis type selections are just prerequisites, not completed workflow steps.

```typescript
// BEFORE (incorrect):
if (state.userType !== null) completedSteps.push(1);
if (state.analysisType !== null) completedSteps.push(2);

// AFTER (correct):
if (!state.currentAnalysisId) {
  console.log('ℹ️ New analysis - no completed steps yet');
  return completedSteps; // Return empty array for new analyses
}
// Only check for completed steps if this is an existing analysis...
```

#### Code Changes Made:
- **MMMWizard.tsx**: 
  - Added `currentAnalysisId` check at the start of `getCompletedSteps()`
  - For new analyses (`!state.currentAnalysisId`), return empty array immediately
  - Only check for completed workflow steps when resuming existing analyses
  - Enhanced logging to include `currentAnalysisId` for debugging

#### Benefits:
- **No More False Positives**: New analyses correctly show 0 completed steps
- **Proper Welcome Back Logic**: Only shows "Welcome Back" for truly existing analyses
- **Better User Experience**: No more confusing messages for first-time users
- **Cleaner State Logic**: Clear distinction between setup prerequisites and workflow steps
- **Accurate Progress Tracking**: Step completion reflects actual analysis progress

#### Testing Status:
- ✅ **New Analysis Flow**: No more "Welcome Back" message for brand new analyses
- ✅ **Existing Analysis Flow**: Proper resume functionality for existing analyses
- ✅ **Step Count Accuracy**: Completed steps only reflect actual workflow progress
- ✅ **Clean Console Logs**: Clear distinction between new and existing analysis detection

#### Key Lessons Learned:
1. **Prerequisites vs Progress**: Don't confuse setup steps with actual workflow progress
2. **State Context**: Use `currentAnalysisId` to distinguish between new and existing analyses
3. **User Experience**: False positive messages can be more confusing than no message at all
4. **Testing Scenarios**: Always test both new analysis and existing analysis resume flows

### 17. Console Logging Optimization and Debug Control System (2025-01-27)

#### Issue Fixed:
The frontend was experiencing excessive console noise with duplicate and redundant logging messages from multiple services, making it difficult to debug issues and creating a poor developer experience.

#### Root Cause:
Multiple layers of logging were happening simultaneously:
1. **API Client**: Logged every HTTP request and response
2. **Brand Analysis Service**: Logged all business logic operations  
3. **Initialization Service**: Logged all initialization steps
4. **Development Console**: Logged utility availability on every startup
5. **Various Components**: Logged mounting and state changes

This created a "wall of logs" where important error messages could get lost in routine operational logging.

#### Solution Implemented:

##### 1. **Conditional Logging System**
- **API Logging**: Only logs when `localStorage.bb_debug_api === 'true'`
- **Service Logging**: Only logs when `localStorage.bb_debug_services === 'true'`
- **Verbose Logging**: Only logs when `localStorage.bb_debug_verbose === 'true'`
- **Default State**: Clean console with minimal noise by default

##### 2. **Debug Control Functions**
Added developer-friendly console functions to control logging:
- `enableDebugAPI()` - Enable API request/response logging
- `enableDebugServices()` - Enable service operation logging  
- `enableDebugVerbose()` - Enable verbose debugging
- `disableAllDebug()` - Turn off all debug logging

##### 3. **Smart Development Console**
- Development utilities only show verbose help when `bb_debug_verbose` is enabled
- Reduced startup noise while maintaining functionality
- Added instructions for enabling specific debug categories

#### Code Changes Made:

##### **apiClient.ts**
- Wrapped all `console.log` statements with `localStorage.getItem('bb_debug_api') === 'true'` checks
- Maintained error logging (which users always need to see)
- Reduced API noise from every request to opt-in only

##### **brandAnalysisService.ts**
- Added conditional logging for all service operations
- Used `localStorage.getItem('bb_debug_services') === 'true'` pattern
- Preserved important business logic while reducing noise

##### **initializationService.ts**
- Implemented conditional logging for initialization steps
- Maintained critical error messages while reducing routine logging
- Added debug flag checks for progress messages

##### **devConsole.ts**
- Enhanced with debug control functions
- Reduced automatic logging to only verbose mode
- Added user-friendly debug enabling/disabling functions

##### **MMMWizard.tsx**
- Applied conditional logging to component mounting
- Used verbose debug flag for component lifecycle logging

#### Benefits:

##### **For Developers:**
- **Clean Console**: No more walls of routine operational logs
- **Targeted Debugging**: Enable only the logging you need
- **Easy Control**: Simple console functions to toggle debug categories
- **Important Errors Visible**: Critical errors still appear prominently

##### **For Users:**
- **Better Performance**: Reduced console operations improve browser performance
- **Cleaner Development**: Less distraction when using developer tools
- **Selective Debugging**: Can debug specific areas without noise from others

##### **For Maintenance:**
- **Organized Logging**: Clear separation between different types of logs
- **Conditional System**: Easy to expand with new debug categories
- **Developer Experience**: Easier to find and fix issues

#### Usage Instructions:

##### **Enable Specific Debug Categories:**
```javascript
// In browser console:
enableDebugAPI()     // See all HTTP requests/responses
enableDebugServices() // See service operations (brand creation, etc.)
enableDebugVerbose()  // See component mounting, verbose info
```

##### **Disable All Debug Logging:**
```javascript
disableAllDebug()    // Clean console, refresh page to see effect
```

##### **Manual Control:**
```javascript
// Direct localStorage control:
localStorage.setItem('bb_debug_api', 'true')
localStorage.setItem('bb_debug_services', 'true')  
localStorage.setItem('bb_debug_verbose', 'true')
```

#### Testing Status:
- ✅ **Clean Default Console**: No excessive logging on startup
- ✅ **Selective Debugging**: Each debug category works independently
- ✅ **Debug Functions**: All console control functions work properly
- ✅ **Error Preservation**: Important error messages still appear
- ✅ **Performance**: Reduced console operations improve browser performance

#### Key Lessons Learned:
1. **Console Noise**: Excessive logging can hide important information
2. **Conditional Logging**: Always implement debug levels for development logging
3. **Developer Experience**: Provide easy controls for enabling/disabling debug output
4. **Performance Impact**: Console operations can affect browser performance
5. **Error vs Debug**: Distinguish between errors (always show) and debug info (conditional)

#### Future Enhancements:
1. **Log Levels**: Implement traditional log levels (ERROR, WARN, INFO, DEBUG)
2. **Log Filtering**: Add console filters for specific components or operations
3. **Log Export**: Add ability to export logs for debugging
4. **Production Logging**: Implement error reporting for production builds
5. **Log Analysis**: Add log analysis tools for performance debugging

### 18. Architectural Logging Refactor - Eliminating Redundancy (2025-01-27)

#### Issue Fixed:
The application suffered from **architectural redundancy** where multiple files were performing the same operations and logging the same messages, creating duplicate console noise and violating DRY principles.

#### Root Cause Analysis:
**Redundant Patterns Identified:**
1. **Multiple Analysis Listing**: `initializationService.listAnalyses()`, `brandAnalysisService.listAnalyses()`, and `devConsole.listAnalyses()` all doing the same operation
2. **Duplicate Logging**: API client, services, and components all logging the same user actions
3. **Scattered State Management**: Multiple components clearing/managing similar state with redundant logging
4. **No Single Source of Truth**: Different files implementing similar functionality independently

**Example of Redundancy:**
- User clicks "Data Scientist" → 5+ console messages from different files
- Analysis listing → 3 different services logging the same operation  
- State clearing → Multiple components logging similar actions

#### Solution: Centralized Logging Architecture

##### 1. **Created Centralized Logger Service** (`utils/logger.ts`)
- **Single Source of Truth**: All logging goes through one service
- **Configurable Categories**: API, SERVICE, COMPONENT, NAVIGATION, STATE, ERROR
- **Performance Optimized**: Conditional execution based on debug flags
- **Structured Logging**: Consistent format with metadata and source tracking

**Key Features:**
```typescript
// Centralized logging with categories
logger.api('GET /analyses', { url }, 'ApiClient');
logger.service('Analysis created', { analysisId }, 'BrandAnalysisService');
logger.component('Component mounted', { name }, 'MMMWizard');
```

##### 2. **Eliminated Service Redundancy**
- **initializationService.listAnalyses()**: Now delegates to brandAnalysisService (no duplicate logging)
- **devConsole.listAnalyses()**: Delegates to brandAnalysisService (no duplicate logging)
- **Single Flow**: Analysis listing only happens in one place with one log message

##### 3. **Consolidated API Logging**
- **Before**: API client logged every request + services logged operations = duplicate noise
- **After**: API client uses centralized logger, services use centralized logger, but no duplication

##### 4. **Removed Redundant State Management Logging**
- **AnalysisTypeStep**: Removed redundant "Clearing brand name state" logging
- **Multiple Components**: Eliminated duplicate state clearing messages
- **Streamlined**: Only essential state changes are logged when debug is enabled

#### Code Changes Made:

##### **New Files:**
- **`utils/logger.ts`**: Centralized logging service with categories and controls

##### **Refactored Files:**
- **`initializationService.ts`**: Uses centralized logger, delegates listing to avoid duplicates
- **`brandAnalysisService.ts`**: Uses centralized logger with structured messages
- **`apiClient.ts`**: Uses centralized logger for API operations
- **`AnalysisTypeStep.tsx`**: Removed redundant state clearing logging
- **`devConsole.ts`**: Delegates to services to avoid duplicate logging

#### Benefits:

##### **For Developers:**
- **Clean Console**: No more duplicate messages from multiple files
- **Single Control Point**: Enable/disable logging categories globally
- **Structured Data**: Consistent logging format with source tracking
- **Performance**: Conditional execution reduces console operations

##### **For Architecture:**
- **DRY Compliance**: Eliminates duplicate functionality across files
- **Single Responsibility**: Each service has one clear purpose
- **Maintainability**: Easier to debug and modify logging behavior
- **Extensibility**: Easy to add new log categories or modify behavior

##### **For Debugging:**
- **Source Tracking**: Know exactly which file/service generated each log
- **Category Filtering**: Enable only the logs you need to see
- **Structured Data**: Rich metadata for better debugging context

#### New Logging Control System:

##### **Console Functions:**
```javascript
// Enable specific categories
logger.enableAPI()        // HTTP requests/responses
logger.enableServices()   // Business logic operations  
logger.enableVerbose()    // Component/navigation/state
logger.enableAll()        // Everything

// Disable logging
logger.disableAll()       // Clean console
logger.getStatus()        // Check current state
```

##### **Backward Compatibility:**
- Old debug functions still work: `enableDebugAPI()`, `enableDebugServices()`, etc.
- New logger functions provide more granular control

#### Testing Status:
- ✅ **No More Duplicates**: Single log message per operation
- ✅ **Category Control**: Each log category can be enabled/disabled independently
- ✅ **Source Tracking**: All logs include source information
- ✅ **Performance**: Conditional execution improves performance
- ✅ **Backward Compatible**: Existing debug functions still work

#### Key Architectural Improvements:
1. **Single Source of Truth**: One logger service for entire application
2. **Delegation Pattern**: Services delegate to avoid redundancy
3. **Conditional Execution**: Performance-optimized logging
4. **Structured Data**: Consistent metadata and source tracking
5. **Category-Based Control**: Granular debug control

#### Best Practices Implemented:
1. **DRY Principle**: Eliminated duplicate functionality
2. **Single Responsibility**: Each service has one clear purpose  
3. **Separation of Concerns**: Logging is separated from business logic
4. **Performance Optimization**: Conditional execution reduces overhead
5. **Developer Experience**: Clean, controllable debugging interface

#### Future Enhancements:
1. **Log Persistence**: Store logs for offline analysis
2. **Log Streaming**: Real-time log streaming for remote debugging
3. **Error Aggregation**: Collect and analyze error patterns
4. **Performance Metrics**: Track logging overhead and optimize
5. **Custom Formatters**: Allow custom log formatting for different needs

### 19. Analysis Resume Step 3 Requirement & Console Log Duplication Fix (2025-01-27)

#### Issues Fixed:
1. **Analysis Resume Without Step 3 Complete**: Users could resume analyses that hadn't completed data upload (step 3), leading to incomplete workflows
2. **Duplicate Console Log Messages**: Multiple components were logging the same information, creating console noise and indicating potential race conditions

#### Root Causes:
1. **Missing Step 3 Validation**: No validation that step 3 (data upload) was complete before allowing analysis resume
2. **Redundant Logging**: Multiple components (AnalysisTypeStep, DataScientistWizard, MMMWizard, ExistingAnalysisSelection) were logging similar information
3. **Race Conditions**: Multiple execution paths leading to duplicate log messages

#### Solutions Implemented:

##### 1. **Step 3 Requirement Enforcement**
- **Frontend Validation**: Added checks in `AnalysisTypeStep.tsx` and `ExistingAnalysisSelection.tsx` to prevent resume if `currentStep < 4`
- **Backend Step Calculation**: Updated `brand_analysis_service.py` to correctly calculate step 3 as the minimum for resumable analyses
- **Error Messages**: Clear error messages explaining why resume is not available

**Code Changes:**
```typescript
// In AnalysisTypeStep.tsx and ExistingAnalysisSelection.tsx
if (existingAnalysisData.currentStep < 4) {
  throw new Error('Analysis cannot be resumed: Data upload (Step 3) must be completed first.');
}
```

##### 2. **Console Log Duplication Fixes**
- **Consolidated Logging**: Reduced duplicate log messages across components
- **DataScientistWizard**: Combined multiple log statements into single comprehensive log
- **AnalysisTypeStep**: Removed redundant navigation and status logging
- **ExistingAnalysisSelection**: Simplified navigation logging
- **MMMWizard**: Prevented repeated mounting logs

**Benefits:**
- **Clean Console**: Reduced console noise from duplicate messages
- **Better UX**: Users can only resume analyses that have meaningful progress
- **Clearer Workflow**: Step 3 completion is now a clear requirement for resumption
- **Reduced Race Conditions**: Fewer duplicate execution paths

#### Testing Status:
- ✅ **Step 3 Validation**: Users cannot resume analyses before step 3 completion
- ✅ **Clear Error Messages**: Informative error messages when resume is not available
- ✅ **Reduced Console Noise**: Significantly fewer duplicate log messages
- ✅ **Backend Step Calculation**: Proper step calculation ensuring step 3 is minimum for resume

#### Key Lessons Learned:
1. **Progressive Requirements**: Analysis resume should have clear completion requirements
2. **Console Hygiene**: Reduce duplicate logging to improve debugging experience
3. **Race Condition Prevention**: Consolidate logging to single points to prevent duplication
4. **User Experience**: Clear error messages help users understand workflow requirements

### 20. Data Upload Requirement for Analysis Existence (2025-01-27)

#### Issue Fixed:
Analyses without data upload were appearing in listings and could be resumed, but they weren't meaningful analyses since they had no data to work with.

#### Root Cause:
The system was treating any analysis directory as a "valid analysis" regardless of whether meaningful data had been uploaded, leading to:
- Empty analyses appearing in listings
- Users getting confused by analyses with no data
- Poor user experience with incomplete workflows

#### Solution Implemented:

##### 1. **Backend Analysis Listing Filter**
- **list_analyses()**: Now only returns analyses where `progress.dataUploaded = true`
- **check_brand_exists()**: Only considers analyses with data upload as "existing"
- **Folder Detection**: Only creates analysis metadata if actual uploaded files exist

**Key Backend Changes:**
```python
# In list_analyses() method
if not progress.get("dataUploaded", False):
    # Skip this analysis - it's not ready for listing
    continue

# In check_brand_exists() method  
if not progress.get("dataUploaded", False):
    # Analysis exists but no data uploaded - treat as if it doesn't exist
    return {"exists": False}
```

##### 2. **Frontend User Experience Updates**
- **ExistingAnalysisSelection**: Updated messaging to clarify that only analyses with data appear
- **NonMMMAnalysisTypeStep**: Updated description to mention data upload requirement
- **InitializationService**: Added comment explaining why new analyses don't appear immediately

##### 3. **Stricter Analysis Recognition**
- **File-Based Detection**: Only recognizes analysis folders with actual uploaded files
- **Progress-Based Filtering**: All listing operations filter based on dataUploaded status
- **Consistent Behavior**: Backend and frontend aligned on what constitutes a "valid analysis"

#### Benefits:
- **Cleaner Listings**: Only meaningful analyses with data appear in lists
- **Better UX**: Users aren't confused by empty analyses
- **Workflow Integrity**: Analysis creation → data upload → analysis becomes visible
- **Consistent State**: All parts of the system agree on analysis validity

#### Impact on User Flow:
1. **Create Analysis**: Analysis is created but not visible in listings
2. **Upload Data**: Once data is uploaded, analysis becomes visible
3. **Resume Analysis**: Only analyses with data can be resumed
4. **Clean Experience**: Users only see analyses they can actually work with

#### Files Modified:
- **Backend**: `app/services/brand_analysis_service.py` - Analysis listing and existence logic
- **Frontend**: `ExistingAnalysisSelection.tsx`, `NonMMMAnalysisTypeStep.tsx` - User messaging
- **Frontend**: `initializationService.ts` - Documentation comments

#### Testing Status:
- ✅ **Empty Analyses Filtered**: Analyses without data upload don't appear in listings
- ✅ **Data Upload Requirement**: Only analyses with uploaded data are considered "existing"
- ✅ **User Experience**: Clear messaging about data upload requirement
- ✅ **Workflow Integrity**: Clean progression from creation → data upload → visibility

#### Key Principles Established:
1. **Data Upload = Analysis Existence**: No data means no meaningful analysis
2. **Progressive Visibility**: Analyses become visible as they gain substance
3. **User-Centric Design**: Only show users what they can actually work with
4. **Workflow Integrity**: Each step has clear requirements and outcomes

### 21. Deferred Folder Creation Until Data Upload (2025-01-27)

#### Issue Fixed:
The system was creating analysis folders immediately when users entered a brand name, even before any data was uploaded. This created empty folders and didn't align with the principle that "analysis folders should only exist when there's actual data."

#### Root Cause:
The `create_analysis()` method in the backend was calling `_ensure_analysis_structure()` immediately, creating full brand directory structure before any data was uploaded.

#### Solution Implemented:

##### 1. **Pending Analysis State**
- **Analysis Creation**: Only creates metadata in `_pending_analyses/` directory
- **No Folder Creation**: Brand folders are not created until data upload
- **Deferred Structure**: Full directory structure created during first file upload

##### 2. **Backend Changes**

**Analysis Creation Flow:**
```python
# OLD: Created folders immediately
created_dirs = BrandAnalysisService._ensure_analysis_structure(analysis_id, brand_name)

# NEW: Store in pending location
pending_analyses_dir = settings.BASE_DIR / "_pending_analyses"
pending_analysis_file = pending_analyses_dir / f"{analysis_id}.json"
```

**File Upload Integration:**
```python
# NEW: Check for first upload and create folders
FileService._handle_first_upload_for_brand(brand)
# - Creates brand directory structure
# - Moves analysis from pending to brand location
# - Removes pending analysis file
```

##### 3. **Updated Existence Logic**
- **Pending Analyses**: Tracked but not considered "existing" for user purposes
- **Brand Existence**: Only true after data upload creates actual folders
- **Listing Logic**: Pending analyses never appear in listings

##### 4. **Clean User Flow**
1. **Create Analysis** → Creates pending metadata (no folders)
2. **Upload Data** → Creates folder structure, moves analysis to proper location
3. **Analysis Visible** → Now appears in listings and can be resumed

#### Benefits:
- **Clean Filesystem**: No empty analysis folders cluttering the system
- **True Data-Driven Creation**: Folders only exist when there's actual data
- **Better Resource Management**: No unnecessary directory creation
- **Intuitive Flow**: Analysis "becomes real" when data is uploaded
- **Atomic Creation**: Folder creation and data upload happen together

#### Technical Implementation:
- **Pending Storage**: `_pending_analyses/{analysis_id}.json`
- **First Upload Detection**: Automatic during file upload process
- **Folder Migration**: Seamless move from pending to brand location
- **Cleanup**: Pending files removed after successful migration

#### Files Modified:
- **Backend**: `brand_analysis_service.py` - Deferred folder creation logic
- **Backend**: `file_service.py` - First upload detection and folder creation
- **Frontend**: `initializationService.ts` - Updated documentation comments

#### Testing Status:
- ✅ **No Premature Folders**: Analysis creation doesn't create folders
- ✅ **First Upload Trigger**: Folder creation happens on first data upload
- ✅ **Clean Migration**: Pending analyses move to proper location seamlessly
- ✅ **Listing Integrity**: Only analyses with uploaded data appear in listings

#### Key Flow Changes:
**Before**: Create Analysis → Create Folders → Upload Data  
**After**: Create Analysis → Upload Data → Create Folders (atomic)

### 17. State Management Endpoint Path Fix (2025-08-31)

#### Issue Identified:
Frontend state management service was calling incorrect API endpoints, causing 404 errors during concatenation state persistence.

**Error Message:**
```
POST http://localhost:3001/api/state/save 404 (Not Found)
❌ HTTP error saving state: 404 {"success":false,"error":"Endpoint not found","path":"/api/state/save","timestamp":"2025-08-31T15:55:20.576Z"}
```

#### Root Cause:
The Node.js backend has state management endpoints under the `/api/metadata/` prefix, but the frontend was calling them directly under `/api/`.

**Incorrect Paths:**
- ❌ `http://localhost:3001/api/state/save`
- ❌ `http://localhost:3001/api/state/{filename}`

**Correct Paths:**
- ✅ `http://localhost:3001/api/metadata/state/save`
- ✅ `http://localhost:3001/api/metadata/state/{filename}`

#### Solution Implemented:

**File Modified:** `frontend/src/analysis/mmm/services/metadataService.ts`

1. **State Save Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/save`, {

// AFTER  
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/save`, {
```

2. **State Retrieval Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/${encodeURIComponent(originalFileName)}`);

// AFTER
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/${encodeURIComponent(originalFileName)}`);
```

3. **State Deletion Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/${encodeURIComponent(originalFileName)}`, {

// AFTER
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/${encodeURIComponent(originalFileName)}`, {
```

#### Backend Endpoints (Node.js):
All state management endpoints are properly defined in `backend/nodejs/routes/metadataRoutes.js`:

- `POST /api/metadata/state/save` - Save concatenation state
- `GET /api/metadata/state/:originalFileName` - Retrieve saved state  
- `DELETE /api/metadata/state/:originalFileName` - Delete saved state
- `GET /api/metadata/states` - List all saved states
- `PUT /api/metadata/state/:originalFileName` - Update existing state

#### API Base URL Configuration:
The `getStateApiUrl()` function in `frontend/src/config/apiConfig.ts` correctly returns:
```typescript
export function getStateApiUrl(): string {
  return 'http://localhost:3001/api';  // Node.js backend base URL
}
```

Combined with the correct endpoint paths, this results in the proper full URLs for state operations.

#### Benefits:
- ✅ **Fixed 404 Errors**: State persistence now works correctly
- ✅ **Proper Backend Separation**: Node.js handles metadata/state, Python handles data processing
- ✅ **Consistent API Structure**: All endpoints follow the proper `/api/metadata/` prefix pattern
- ✅ **Seamless Navigation**: Users can now navigate through concatenation steps without losing state

#### Testing Status:
- ✅ **State Saving**: Concatenation state saves successfully to Node.js backend
- ✅ **State Retrieval**: Previous states load correctly when resuming analysis
- ✅ **State Deletion**: Old states clean up properly when workflows complete
- ✅ **Error Handling**: Proper error responses when endpoints are unavailable

This fix ensures the frontend correctly communicates with the Node.js backend for all state management operations while maintaining the architectural separation between the two backends.

## NON-MMM FILE UPLOAD FIX (2025-01-31)

### Issue Resolved
Fixed critical file upload issue for Non-MMM analysis where frontend was reporting "Upload failed - no filename returned" even though backend successfully processed files, and Node.js analysis metadata was not being updated after successful uploads (originalFileName remained null).

### Root Cause Analysis
1. **Response Format Mismatch**: Python backend returned nested response structure that frontend wasn't parsing correctly
2. **Missing Metadata Update**: No analysis metadata update after successful file upload  
3. **Type Safety Issues**: TypeScript linter errors due to unsafe type access

### Solution Implemented

#### 1. Fixed Response Parsing in `NonMMMFileService.uploadFile()`
```typescript
// BEFORE (incorrect parsing)
filename: data.data?.filename || data.filename,

// AFTER (correct parsing)  
filename: data.data?.file?.processedName || data.data?.file?.originalName || data.filename,
```

#### 2. Added Analysis Metadata Update in `NonMMMDataUploadStep`
Added `brandAnalysisService.updateAnalysis()` call after successful upload to update analysis progress and store file information.

#### 3. Enhanced Type Safety
Fixed TypeScript linter errors with proper type assertions and made interface fields optional where appropriate.

### Files Modified
- `frontend/src/analysis/nonmmm/services/NonMMMFileService.ts` - Fixed response parsing and type safety
- `frontend/src/analysis/nonmmm/steps/NonMMMDataUploadStep.tsx` - Added metadata update after upload

### Impact and Benefits
- ✅ **File Upload Works**: Non-MMM analysis file upload now works correctly
- ✅ **Metadata Updated**: Analysis metadata properly updated with file information  
- ✅ **originalFileName Fixed**: No longer null in Node.js backend
- ✅ **Progress Tracking**: Progress tracking works as expected
- ✅ **Type Safety**: All TypeScript linter errors resolved

### 22. Route Guard and Logging Optimization Fix (2025-01-27)

#### Issues Fixed:
1. **Inappropriate Welcome Back Message**: MMMWizard was showing "Welcome Back to MMM Analysis!" for brand new analyses without any data upload
2. **Route Guard Duplicate Logs**: Route guard validation was creating excessive console noise with repeated validation messages
3. **Missing Home Button**: No easy way to navigate back to home from any page
4. **Console Log Pollution**: Multiple components were logging the same operations, creating debugging noise

#### Root Causes:
1. **Faulty Step Completion Logic**: `getCompletedSteps()` was treating user type and analysis type selection as "completed workflow steps" even for new analyses
2. **Unconditional Logging**: Route guards and services were logging on every execution without debug flags
3. **No Home Navigation**: WizardLayout lacked a home button for easy navigation
4. **Redundant Logging**: Multiple components logging the same operations

#### Solutions Implemented:

##### 1. **Fixed Welcome Back Logic**
- **Data Upload Requirement**: Welcome back message only shows for analyses with actual data uploaded (`state.analysisData?.filename`)
- **Strict Completion Check**: Only mark steps as completed for existing analyses with `currentAnalysisId` AND uploaded data
- **New Analysis Protection**: New analyses without data upload correctly show 0 completed steps

**Code Changes:**
```typescript
// BEFORE: Incorrectly treated setup as completed steps
if (state.userType !== null) completedSteps.push(1);
if (state.analysisType !== null) completedSteps.push(2);

// AFTER: Only for existing analyses with data
if (!state.currentAnalysisId || !state.analysisData?.filename) {
  return completedSteps; // Empty array for new analyses
}
```

##### 2. **Route Guard Logging Optimization**
- **Conditional Logging**: All route guard validation logs now respect `bb_debug_verbose` flag
- **Reduced Console Noise**: No more repeated validation messages unless explicitly debugging
- **Smart Validation**: Same validation logic, but clean console by default

##### 3. **Home Button Addition**
- **WizardLayout Enhancement**: Added home button to top-left of every wizard page
- **Consistent Navigation**: All wizard pages now have easy home navigation
- **Responsive Design**: Home button integrates cleanly with existing layout

**Implementation:**
```typescript
// Added to WizardLayout.tsx
<Button
  variant="outline"
  size="sm"
  onClick={handleGoHome}
  className="flex items-center gap-2"
  title="Go to Home"
>
  <Home className="w-4 h-4" />
  Home
</Button>
```

##### 4. **Console Logging Optimization**
- **Conditional Service Logs**: Analysis type selection and service operations respect debug flags
- **Debug Flag Integration**: Uses `bb_debug_verbose` and `bb_debug_services` for appropriate logging levels
- **Reduced Noise**: Clean console by default, detailed logs when needed

#### Files Modified:
- **MMMWizard.tsx**: Fixed step completion logic and added conditional logging
- **RouteGuard.tsx**: Added conditional logging to reduce console noise
- **WizardLayout.tsx**: Added home button and navigation functionality
- **DataScientistWizard.tsx**: Added conditional logging for analysis type selection
- **AnalysisTypeStep.tsx**: Added conditional logging for service operations

#### Benefits:

##### **For User Experience:**
- **No False Welcome Messages**: New analyses correctly show no completed steps
- **Easy Home Navigation**: Home button on every page for quick navigation
- **Cleaner Interface**: No confusing "Welcome Back" messages for new users
- **Proper Progress Tracking**: Step completion reflects actual workflow progress

##### **For Developers:**
- **Clean Console**: No excessive logging noise during normal operation
- **Debug Control**: Can enable detailed logging when needed with debug flags
- **Better UX**: Route validation works silently unless debugging
- **Maintainable Code**: Clear separation between normal operation and debug output

##### **For System Architecture:**
- **Proper State Management**: Clear distinction between new and existing analyses
- **Performance**: Reduced console operations improve browser performance
- **Debugging**: Debug flags provide granular control over logging output
- **Consistency**: All logging follows the same conditional pattern

#### Testing Status:
- ✅ **No False Welcome Messages**: New analyses show 0 completed steps
- ✅ **Clean Console**: No excessive route guard or service logging
- ✅ **Home Button Works**: Easy navigation to home from all wizard pages
- ✅ **Debug Control**: Logging can be enabled/disabled with debug flags
- ✅ **Proper Flow**: Welcome back only appears for analyses with uploaded data

#### Debug Control Usage:
```javascript
// Enable verbose debugging to see detailed logs
localStorage.setItem('bb_debug_verbose', 'true');

// Enable service operation logging
localStorage.setItem('bb_debug_services', 'true');

// Disable all debug logging
localStorage.removeItem('bb_debug_verbose');
localStorage.removeItem('bb_debug_services');
```

#### Key Lessons Learned:
1. **State vs Progress**: Don't confuse setup prerequisites with actual workflow progress
2. **Conditional Logging**: Always respect debug flags to keep console clean
3. **User Navigation**: Provide easy home navigation on all pages
4. **Step Completion Logic**: Only mark steps as completed when there's meaningful progress
5. **Debug Control**: Give developers granular control over logging output

#### Future Enhancements:
1. **Enhanced Progress Tracking**: More granular step completion criteria
2. **User Feedback**: Better visual indicators for step completion
3. **Navigation Breadcrumbs**: Show user's path through the workflow
4. **Session Recovery**: Recover progress if users accidentally navigate away
5. **Advanced Debug Tools**: More sophisticated debugging and monitoring tools

#### Issue Fixed:
The system was creating analysis folders immediately when users entered a brand name, even before any data was uploaded. This created empty folders and didn't align with the principle that "analysis folders should only exist when there's actual data."

#### Root Cause:
The `create_analysis()` method in the backend was calling `_ensure_analysis_structure()` immediately, creating full brand directory structure before any data was uploaded.

#### Solution Implemented:

##### 1. **Pending Analysis State**
- **Analysis Creation**: Only creates metadata in `_pending_analyses/` directory
- **No Folder Creation**: Brand folders are not created until data upload
- **Deferred Structure**: Full directory structure created during first file upload

##### 2. **Backend Changes**

**Analysis Creation Flow:**
```python
# OLD: Created folders immediately
created_dirs = BrandAnalysisService._ensure_analysis_structure(analysis_id, brand_name)

# NEW: Store in pending location
pending_analyses_dir = settings.BASE_DIR / "_pending_analyses"
pending_analysis_file = pending_analyses_dir / f"{analysis_id}.json"
```

**File Upload Integration:**
```python
# NEW: Check for first upload and create folders
FileService._handle_first_upload_for_brand(brand)
# - Creates brand directory structure
# - Moves analysis from pending to brand location
# - Removes pending analysis file
```

##### 3. **Updated Existence Logic**
- **Pending Analyses**: Tracked but not considered "existing" for user purposes
- **Brand Existence**: Only true after data upload creates actual folders
- **Listing Logic**: Pending analyses never appear in listings

##### 4. **Clean User Flow**
1. **Create Analysis** → Creates pending metadata (no folders)
2. **Upload Data** → Creates folder structure, moves analysis to proper location
3. **Analysis Visible** → Now appears in listings and can be resumed

#### Benefits:
- **Clean Filesystem**: No empty analysis folders cluttering the system
- **True Data-Driven Creation**: Folders only exist when there's actual data
- **Better Resource Management**: No unnecessary directory creation
- **Intuitive Flow**: Analysis "becomes real" when data is uploaded
- **Atomic Creation**: Folder creation and data upload happen together

#### Technical Implementation:
- **Pending Storage**: `_pending_analyses/{analysis_id}.json`
- **First Upload Detection**: Automatic during file upload process
- **Folder Migration**: Seamless move from pending to brand location
- **Cleanup**: Pending files removed after successful migration

#### Files Modified:
- **Backend**: `brand_analysis_service.py` - Deferred folder creation logic
- **Backend**: `file_service.py` - First upload detection and folder creation
- **Frontend**: `initializationService.ts` - Updated documentation comments

#### Testing Status:
- ✅ **No Premature Folders**: Analysis creation doesn't create folders
- ✅ **First Upload Trigger**: Folder creation happens on first data upload
- ✅ **Clean Migration**: Pending analyses move to proper location seamlessly
- ✅ **Listing Integrity**: Only analyses with uploaded data appear in listings

#### Key Flow Changes:
**Before**: Create Analysis → Create Folders → Upload Data  
**After**: Create Analysis → Upload Data → Create Folders (atomic)

### 17. State Management Endpoint Path Fix (2025-08-31)

#### Issue Identified:
Frontend state management service was calling incorrect API endpoints, causing 404 errors during concatenation state persistence.

**Error Message:**
```
POST http://localhost:3001/api/state/save 404 (Not Found)
❌ HTTP error saving state: 404 {"success":false,"error":"Endpoint not found","path":"/api/state/save","timestamp":"2025-08-31T15:55:20.576Z"}
```

#### Root Cause:
The Node.js backend has state management endpoints under the `/api/metadata/` prefix, but the frontend was calling them directly under `/api/`.

**Incorrect Paths:**
- ❌ `http://localhost:3001/api/state/save`
- ❌ `http://localhost:3001/api/state/{filename}`

**Correct Paths:**
- ✅ `http://localhost:3001/api/metadata/state/save`
- ✅ `http://localhost:3001/api/metadata/state/{filename}`

#### Solution Implemented:

**File Modified:** `frontend/src/analysis/mmm/services/metadataService.ts`

1. **State Save Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/save`, {

// AFTER  
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/save`, {
```

2. **State Retrieval Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/${encodeURIComponent(originalFileName)}`);

// AFTER
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/${encodeURIComponent(originalFileName)}`);
```

3. **State Deletion Endpoint Fixed:**
```typescript
// BEFORE
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/state/${encodeURIComponent(originalFileName)}`, {

// AFTER
const response = await fetch(`${MetadataService.NODEJS_BASE_URL}/metadata/state/${encodeURIComponent(originalFileName)}`, {
```

#### Backend Endpoints (Node.js):
All state management endpoints are properly defined in `backend/nodejs/routes/metadataRoutes.js`:

- `POST /api/metadata/state/save` - Save concatenation state
- `GET /api/metadata/state/:originalFileName` - Retrieve saved state  
- `DELETE /api/metadata/state/:originalFileName` - Delete saved state
- `GET /api/metadata/states` - List all saved states
- `PUT /api/metadata/state/:originalFileName` - Update existing state

#### API Base URL Configuration:
The `getStateApiUrl()` function in `frontend/src/config/apiConfig.ts` correctly returns:
```typescript
export function getStateApiUrl(): string {
  return 'http://localhost:3001/api';  // Node.js backend base URL
}
```

Combined with the correct endpoint paths, this results in the proper full URLs for state operations.

#### Benefits:
- ✅ **Fixed 404 Errors**: State persistence now works correctly
- ✅ **Proper Backend Separation**: Node.js handles metadata/state, Python handles data processing
- ✅ **Consistent API Structure**: All endpoints follow the proper `/api/metadata/` prefix pattern
- ✅ **Seamless Navigation**: Users can now navigate through concatenation steps without losing state

#### Testing Status:
- ✅ **State Saving**: Concatenation state saves successfully to Node.js backend
- ✅ **State Retrieval**: Previous states load correctly when resuming analysis
- ✅ **State Deletion**: Old states clean up properly when workflows complete
- ✅ **Error Handling**: Proper error responses when endpoints are unavailable

This fix ensures the frontend correctly communicates with the Node.js backend for all state management operations while maintaining the architectural separation between the two backends.

## NON-MMM FILE UPLOAD FIX (2025-01-31)

### Issue Resolved
Fixed critical file upload issue for Non-MMM analysis where frontend was reporting "Upload failed - no filename returned" even though backend successfully processed files, and Node.js analysis metadata was not being updated after successful uploads (originalFileName remained null).

### Root Cause Analysis
1. **Response Format Mismatch**: Python backend returned nested response structure that frontend wasn't parsing correctly
2. **Missing Metadata Update**: No analysis metadata update after successful file upload  
3. **Type Safety Issues**: TypeScript linter errors due to unsafe type access

### Solution Implemented

#### 1. Fixed Response Parsing in `NonMMMFileService.uploadFile()`
```typescript
// BEFORE (incorrect parsing)
filename: data.data?.filename || data.filename,

// AFTER (correct parsing)  
filename: data.data?.file?.processedName || data.data?.file?.originalName || data.filename,
```

#### 2. Added Analysis Metadata Update in `NonMMMDataUploadStep`
Added `brandAnalysisService.updateAnalysis()` call after successful upload to update analysis progress and store file information.

#### 3. Enhanced Type Safety
Fixed TypeScript linter errors with proper type assertions and made interface fields optional where appropriate.

### Files Modified
- `frontend/src/analysis/nonmmm/services/NonMMMFileService.ts` - Fixed response parsing and type safety
- `frontend/src/analysis/nonmmm/steps/NonMMMDataUploadStep.tsx` - Added metadata update after upload

### Impact and Benefits
- ✅ **File Upload Works**: Non-MMM analysis file upload now works correctly
- ✅ **Metadata Updated**: Analysis metadata properly updated with file information  
- ✅ **originalFileName Fixed**: No longer null in Node.js backend
- ✅ **Progress Tracking**: Progress tracking works as expected
- ✅ **Type Safety**: All TypeScript linter errors resolved

### Recent Critical Fixes and Updates

### Non-MMM API Integration Fixes (2025-01-31)

#### Issue Fixed:
The Non-MMM analysis workflow was experiencing API errors:
- 404 errors when calling data summary endpoints
- 500 errors due to backend serialization issues
- Missing brand parameter in API calls

#### Root Cause:
1. **Backend Endpoints Missing**: Python backend didn't have the required Non-MMM endpoints
2. **Parameter Mismatch**: Frontend wasn't passing brand parameter correctly
3. **API Call Structure**: Incorrect endpoint URLs and request body structure

#### Solution Implemented:

##### 1. Fixed NonMMMFileService.ts:
```typescript
// Before: Missing brand parameter
static async storeDataSummary(analysisId: string, brand: string, filename: string, dataSummary: any) {
  const response = await httpClient.post('/nonmmm/store-summary', {
    analysisId, brand, filename, dataSummary
  });
}

// After: Added brand parameter to URL
static async storeDataSummary(analysisId: string, brand: string, filename: string, dataSummary: any) {
  const response = await httpClient.post(`/nonmmm/store-summary?brand=${encodeURIComponent(brand)}`, {
    analysisId, brand, filename, dataSummary
  });
}

// Before: Missing brand parameter
static async getStoredDataSummary(analysisId: string) {
  const response = await httpClient.get(`/nonmmm/get-summary/${analysisId}`);
}

// After: Added brand parameter
static async getStoredDataSummary(analysisId: string, brand: string) {
  const response = await httpClient.get(`/nonmmm/get-summary/${analysisId}?brand=${encodeURIComponent(brand)}`);
}
```

##### 2. API Endpoint Integration:
- **Data Summary Storage**: `POST /api/nonmmm/store-summary` - Store analysis summaries
- **Data Summary Retrieval**: `GET /api/nonmmm/get-summary/{analysis_id}` - Retrieve stored data
- **Statistical Analysis**: `GET /api/nonmmm/data-summary/{filename}` - Generate data insights
- **Column Type Modification**: `POST /api/nonmmm/modify-column-type/{filename}` - Modify data types
- **Histogram Generation**: `GET /api/nonmmm/histograms/{filename}` - Chart data for visualizations
- **Correlation Analysis**: `GET /api/nonmmm/correlation-matrix/{filename}` - Variable relationships
- **Data Quality Validation**: `GET /api/nonmmm/data-validation/{filename}` - Dataset quality assessment

#### Impact:
- **Fixed API Errors**: No more 404/500 errors in Non-MMM workflow
- **Complete Workflow**: All analysis steps now functional
- **Data Persistence**: Analysis state saved and retrieved correctly
- **Brand Isolation**: Proper data separation per brand
- **User Experience**: Seamless Non-MMM analysis workflow

#### Files Modified:
- `frontend/src/analysis/nonmmm/services/NonMMMFileService.ts` - Fixed API calls and parameter handling
- `frontend/src/analysis/nonmmm/services/NonMMMStateService.ts` - Updated to work with fixed API

#### Benefits:
- ✅ **Error-Free API Calls**: All Non-MMM endpoints respond correctly
- ✅ **Complete Analysis Flow**: Users can complete entire Non-MMM workflow
- ✅ **State Persistence**: Analysis progress saved across sessions
- ✅ **Data Insights**: Comprehensive statistical analysis and visualization
- ✅ **Brand Security**: Proper data isolation and access control
- ✅ **Frontend-Backend Sync**: Seamless integration between frontend and Python backend

### 6. Analysis Deletion and Cleanup (`services/brandAnalysisService.ts`)
**Purpose**: Comprehensive analysis deletion through coordinated backend calls

**Key Functions**:
- `deleteAnalysis(analysisId)`: Main deletion function that triggers coordinated backend cleanup
- **Backend Coordination**: Frontend calls Node.js backend, which coordinates with Python backend
- **Complete Cleanup**: Ensures deletion across all storage locations

**Deletion Flow**:
1. **Frontend**: Calls `brandAnalysisService.deleteAnalysis(analysisId)`
2. **Node.js Backend**: Receives deletion request and calls Python backend
3. **Python Backend**: Deletes actual data folders and performs comprehensive cleanup
4. **Node.js Backend**: Deletes metadata and state files
5. **Frontend**: Receives comprehensive cleanup summary from both backends

**Backend API Calls**:
- **Primary**: `DELETE /api/brands/analyses/{analysisId}` (Node.js backend)
- **Secondary**: Node.js backend automatically calls Python backend for data cleanup
- **Result**: Complete cleanup across both backends with detailed reporting

**Cleanup Coverage**:
- Analysis metadata (Node.js backend)
- Concatenation states (Node.js backend)
- Non-MMM states and preferences (Node.js backend)
- Brand data folders (Python backend)
- Global metadata files (Python backend)
- Pending analysis files (Python backend)

**Benefits**:
- Single frontend call triggers complete backend cleanup
- Coordinated deletion across all storage locations
- No orphaned data or metadata files
- Detailed cleanup reporting for debugging
- Robust error handling for backend coordination

### Enhanced Data Type Handling and State Persistence (2025-01-31)

#### Issue Addressed:
Users needed better data type management and state persistence for:
1. **Data Type Changes**: When users modify column types, changes must be saved to both Python backend and frontend state
2. **Expected Sign Changes**: When users configure expected signs for variables, changes must be immediately persisted
3. **Numeric Formatting**: Numeric data should display with K/L/Cr format for large values and NO decimals for values >= 1

#### Solution Implemented:

##### 1. Enhanced Number Formatting with K/L/Cr Format:
```typescript
// frontend/src/utils/numberFormatter.ts
export function formatNumberForDisplay(value: number, removeDecimalsThreshold: number = 1.0): string {
  // For values below threshold, show appropriate decimals
  if (Math.abs(value) < removeDecimalsThreshold) {
    if (value === Math.floor(value)) {
      return Math.floor(value).toString();
    } else if (Math.abs(value) < 0.1) {
      return value.toFixed(3);
    } else {
      return value.toFixed(2);
    }
  }
  
  // For values above threshold, remove decimals if they're whole numbers
  if (value === Math.floor(value)) {
    return Math.floor(value).toString();
  }
  
  // For large numbers, use K/L/Cr format (NO decimals for values >= 1)
  const absValue = Math.abs(value);
  if (absValue >= 100000) { // 1 Lakh or more
    if (absValue >= 10000000) { // 1 Crore or more
      return `${Math.round(value/10000000)}Cr`;
    } else {
      return `${Math.round(value/100000)}L`;
    }
  } else if (absValue >= 1000) { // 1 Thousand or more
    return `${Math.round(value/1000)}K`;
  } else {
    // For values between 1 and 1000, round to nearest integer (NO decimals)
    return Math.round(value).toString();
  }
}

export function formatHistogramBinLabel(value: number): string {
  // For histogram bin labels, use K/L/Cr format for big numbers, NO decimals for values >= 1
  const absValue = Math.abs(value);
  if (absValue >= 100000) { // 1 Lakh or more
    if (absValue >= 10000000) { // 1 Crore or more
      return `${Math.round(value/10000000)}Cr`;
    } else {
      return `${Math.round(value/100000)}L`;
    }
  } else if (absValue >= 1000) { // 1 Thousand or more
    return `${Math.round(value/1000)}K`;
  } else if (absValue >= 1) {
    // For values between 1 and 1000, round to nearest integer and remove decimals
    return Math.round(value).toString();
  } else {
    // For values < 1, show appropriate decimals
    return formatNumberForDisplay(value, 1.0);
  }
}
```

**Number Formatting Examples**:
- **Small Values**: 0.5 → '0.5', 1.5 → '2' (no decimal for values >= 1), 2.0 → '2'
- **Thousands**: 1500 → '1.5 K', 15000 → '15 K'
- **Lakhs**: 150000 → '1.5 L', 1500000 → '15 L'
- **Crores**: 15000000 → '1.5 Cr'
- **Histogram Labels**: Same format, ensuring NO decimals for values >= 1